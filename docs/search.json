[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "Introduction and Presentation\nVlad’s Learning Diary and general thoughts on Remote Sensing Topics!\ntest does it update\n\n\n\n\nGitHub maximum file upload of 50mb. Source: reddit r/ProgrammerHumor"
  },
  {
    "objectID": "index.html#introduction-and-presentation",
    "href": "index.html#introduction-and-presentation",
    "title": "Vlad Tesniere - Blog and projects",
    "section": "Introduction and Presentation",
    "text": "Introduction and Presentation\nVlad’s Blog and general thoughts on Remote Sensing Topics!\n\nAlthough preferable to follow the blog entries in order, there should be sufficient information (with support from the ‘Common Abbreviations’ page and various mouse-over explanations) to understand each individually.\nI am currently working as a Geo-spatial data scientist at the OECD environment directorate, and a graduate of the Master’s in Social and Geographic Data Science, at the Geography Department at UCL!\n\nThis blog is an opportunity for me to research topics that are of interest to me, therefore you may recognise certain reoccurring topics, such as the inclusion of Bucharest and Paris, two cities in which i have lived for the majority of my life!\nHave fun reading and I hope you find as much interest reading, than I had researching these topics!\nThis work is a good representation of myself, as I aim to continue developing my skills in remote sensing, specially looking continue working on EO and policy recommendation projects!\n\n\n\n\n\n\nPublications\n\n\n\nMain/Co-author:\n\n“Monitoring land cover change to understand biodiversity pressures”\n\nDOI: https://doi.org/10.1787/441a7a6c-en, published December 2024\n\n\n\n“Monitoring exposure to future climate-related hazards”\n\nforthcoming, submitted - publication expected April-May 2025\npaper available on demand\n\n\n“Measuring CO\\(_{2}\\) emissions from land cover and land cover change based on Earth Observations”\n\nforthcoming - publication expected June 2025\ndraft and methodology available on demand\n\n\n\nConference Paper:\n\nLeveraging advances in Language Models for neighbourhood delineation in the London housing market\n\nDOI: https://doi.org/10.5281/zenodo.10897775, published April 2024\n\n\n\nContributor:\n\n“OECD Regions and Cities at a glance 2024”\n\nDOI: https://doi.org/10.1787/f42db3bf-en, published December 2024"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "\n1  Introduction\n",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Policy",
    "section": "",
    "text": "define what a policy actually is\ndefine why it is useful and how we can develop it\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "intro.html#basic-raster-image-processing-and-statistics",
    "href": "intro.html#basic-raster-image-processing-and-statistics",
    "title": "Introducing Remote Sensing - A Bucharest Analysis",
    "section": "Basic Raster image processing and statistics",
    "text": "Basic Raster image processing and statistics\nOur images presented below, were collected on the 27th and 17th of October 2022 for Sentinel and Landsat respectively. They are both true color images (TCI) with the Red, Green and Blue bands present.\n\n\n\n\n\n\n\nSentinel-2 (left) and Landsat-8 (Right) TCI over Bucharest (October 2022)\n\n\n\n We have a more recent view available of the Landsat imagery (24th of October) but prefer not to use it as more impurities are present. We will tackle this in future Diary entries with the introduction of atmospheric correction.\n\n\n\n\nRBG image from 24/10, not used in examples but presented for visibility\n\n\n\n\n\nWe continue to explore our data by looking at the different colour composites in the sentinel images:\n\n\n\n\nAtmospheric Penetration (left), False Colour Infrared (Middle), B1 band (right)\n\n\n\n\nIs it interesting to try and understand what the colours mean in these images. For example, the middle image, False Colour Composite (using bands B8, B4 and B3) aims to show the physiography of the terrain showing soil and land-resources which has been common practice since the 20th century (Reddy et al. (1990)). As our study area is primarily urban (Bucharest located in the bottom-left corner), we see that many of the red colours bands are absorbed, signifying a lack of vegetation in the Capital, compared to rural areas on the right side of the image.\nThe same is true for the left image, the atmospheric penetration, where we recognise distinct urban areas due to the purple/gray cyan colours in the bottom-left corner. Finally, the right side image provides a raw overview of the sentinel imagery, and specifically the B1 band. the B1 band is used for the Coastal and Aerosol information, with a detailed description of Bands available here!"
  },
  {
    "objectID": "intro.html#understanding-the-differences-between-sentinel-2-and-landsat",
    "href": "intro.html#understanding-the-differences-between-sentinel-2-and-landsat",
    "title": "2  Introducing Remote Sensing - A Bucharest Analysis",
    "section": "2.2 Understanding the differences between Sentinel 2 and Landsat",
    "text": "2.2 Understanding the differences between Sentinel 2 and Landsat\nNow that we have images from both sources, we proceed to resample the images to the same resolution. Below we have a comparison of the bands between Sentinel-2 and Landsat-8.\n\n\n\nComparison of Sentinel and Landsat Bands, taken from López-Puigdollers, Mateo-García, and Gómez-Chova (2021)\n\n\nYet this is not enough as in order to make cross-platform comparisons successful! Below we have a detailed overview comparing band resolution between Sentinel and Landsat, with respective links to sources of Table 1 (left) and Table 2 (right)!\n\n\n\n\n\nSentinel-2 (left) and Landsat-8 (right) band comparisons\n\n\n\nWe see that the two platforms share certain similar characteristics, but differences are notable. For example, even if the Blue, Green and Red Channels are present on both, their wavelengths do not overlap perfectly. Furthermore, both platforms do not have all the same bands, with 1,2,3,4 overlapping similarly and B11 and B12 on S-2 working with B6 and B7 on L-8. In our application today, we will only be using Bands 2 to 4 on both, B6 and 7 on Landsat and B8 and 12 on Sentinel.\nMost importantly, these two platforms do not share the same resolutions, with L-8 principally outputting at 30m compared to S-2 between 10, 20 or 60m.\nTo overcome this, we upscale the Sentinel Imagery to Fit the 30m resolution displayed by Landsat. As we decide to focus on Bucharest specifically, we also subset the image to only the city outline using shapefiles provided by GADM. The clipped results are as follows:\n\n\n\n\n\nSentinel-2 (left) and Landsat-8 (right) clipped RBG images of Bucharest (at same resolution)"
  },
  {
    "objectID": "intro.html#my-thoughts-and-interpretation-of-the-tool",
    "href": "intro.html#my-thoughts-and-interpretation-of-the-tool",
    "title": "Introducing Remote Sensing - A Bucharest Analysis",
    "section": "My thoughts and interpretation of the tool",
    "text": "My thoughts and interpretation of the tool\nAs this was my first confrontation with Satellite imagery analysis, I was highly interested in discovering the techniques. I was happy to be able to choose my own study area and focus on my hometown!\nIn terms of analysis, it was enthused to learn about the amount of satellite data freely available on Copernicus Open Access Hub and Earth Explorer! I took the liberty to play around with these tools and fully grasp how they work and how i could use them. The image extraction for L-8 and S-2 was quite straightforward and allowed further exploration than just the Bucharest imagery used here.\nThe following steps which included using SNAP and QGIS to look, analyse, subset and re-sample the L-8 and S-2 images. This was already slightly more complicated as I had to get accustomed to the SNAP application, it’s layout, utilities and characteristics.\nI for example played around with the RBG histogram when portraying my RBG images, notably putting a 100% display to understand how the image statistics work\n\n\n\n\n100% pixel display when getting exploring SNAP\n\n\n\n\nI bumped into several issues early on, where I for example could not do the tasseled cap transformation completely. I understood and successfully presented the scatter plots between bands (B4 and B8). Unfortunately, I was not able to compute the tasseled cap transformation with the specific band equations. This is something I hope to develop on and be able to include in the coming weeks.\n\n\n\n\nBucharest Spectral Feature - tasseled cap scatterplot\n\n\n\n\nFinally, using computational methods to compare the results between L-8 and S-2 bands allowed me to gain a better understand of general functioning of spectral bands. I was happy to have made mistakes in my initial analysis with it’s summary presented below:\n\n\nInitial results of Computation Analysis, with non-equivalent bands between S-2 and L-8\n\n\nIn my first results, I made the mistake of comparing the wrong bands, comparing B8 in S-2 and B6 in Landsat which do not measure similar aspects. For this reason, the Band 4 in the above table fo not make sense, in the Sentinel Observations the grass values being much too high! Furthermore, from a visualisation perspective, the colors are not coordinated with the usually considered colours (i.e. grass as green) which make the presentation of the results more confusing.\nAll in all, this first approach was beneficial and very much enjoyed! Understanding how both S-2 and L-8 bands function was not always easy, but with trial and error the final results make sense! We were able to show comparisons between L-8 and S-2 for locally defined POI’s and provided a good initiation in understanding similarities and differences between platforms.\n\n\n\n\nLefebvre, Antoine, Christophe Sannier, and Thomas Corpetti. 2016. “Monitoring Urban Areas with Sentinel-2A Data: Application to the Update of the Copernicus High Resolution Layer Imperviousness Degree.” Remote Sensing 8 (7): 606. https://doi.org/10.3390/rs8070606.\n\n\nLópez-Puigdollers, Dan, Gonzalo Mateo-García, and Luis Gómez-Chova. 2021. “Benchmarking Deep Learning Models for Cloud Detection in Landsat-8 and Sentinel-2 Images.” Remote Sensing 13 (5): 992. https://doi.org/10.3390/rs13050992.\n\n\nNistor, Constantin, Marina Vîrghileanu, Irina Cârlan, Bogdan-Andrei Mihai, Liviu Toma, and Bogdan Olariu. 2021. “Remote Sensing-Based Analysis of Urban Landscape Change in the City of Bucharest, Romania.” Remote Sensing 13 (12): 2323. https://doi.org/10.3390/rs13122323.\n\n\nReddy, R. S., S. Thayalan, C. R. Shiva Prasad, P. S. A. Reddy, and J. L. Sehgal. 1990. “Utility of Satellite Data for Land Evaluation in Land Use Planning for a Part of Northern Karnataka.” Journal of the Indian Society of Remote Sensing 18 (4): 34–44. https://doi.org/10.1007/BF02997071."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Agapiou, Athos, Dimitrios Alexakis, Kyriacos Themistocleous, and\nDiofantos Hadjimitsis. 2014. “Water Leakage Detection Using Remote\nSensing, Field Spectroscopy and GIS in Semiarid Areas of Cyprus.”\nUrban Water Journal 13 (December): 1–11. https://doi.org/10.1080/1573062X.2014.975726.\n\n\nBalázs, Boglárka, Tibor Bíró, Gareth Dyke, Sudhir Kumar Singh, and\nSzilárd Szabó. 2018. “Extracting Water-Related Features Using\nReflectance Data and Principal Component Analysis of Landsat\nImages.” Hydrological Sciences Journal 63 (2): 269–84.\nhttps://doi.org/10.1080/02626667.2018.1425802.\n\n\nBowyer, Paul, Michaela Schaller, Steffen Bender, and Daniela Jacob.\n2014. “AdaptationAdaptation as ClimateClimate Change Risk\nManagementRisk Management : Methods and Approaches.” In, 1–18. https://doi.org/10.1007/978-3-642-40455-9_28-1.\n\n\nBrown, Christopher F., Steven P. Brumby, Brookie Guzder-Williams, Tanya\nBirch, Samantha Brooks Hyde, Joseph Mazzariello, Wanda Czerwinski, et\nal. 2022. “Dynamic World, Near Real-Time Global 10 m Land Use Land\nCover Mapping.” Scientific Data 9 (1): 251. https://doi.org/10.1038/s41597-022-01307-4.\n\n\nChavez, Pat S. 1996. “Image-Based Atmospheric Corrections -\nRevisited and Improved.”\n\n\nDennison, Philip E., and Dar A. Roberts. 2003. “Endmember\nSelection for Multiple Endmember Spectral Mixture Analysis Using\nEndmember Average RMSE.” Remote Sensing of Environment\n87 (2): 123–35. https://doi.org/10.1016/S0034-4257(03)00135-4.\n\n\nGhimire, Prakash, Deng Lei, and Nie Juan. 2020. “Effect of Image\nFusion on Vegetation Index QualityA Comparative Study from\nGaofen-1, Gaofen-2, Gaofen-4, Landsat-8 OLI and MODIS Imagery.”\nRemote Sensing 12 (10): 1550. https://doi.org/10.3390/rs12101550.\n\n\nGitelson, Anatoly A., Yoram J. Kaufman, and Mark N. Merzlyak. 1996.\n“Use of a Green Channel in Remote Sensing of Global Vegetation\nfrom EOS-MODIS.” Remote Sensing of Environment 58 (3):\n289–98. https://doi.org/10.1016/S0034-4257(96)00072-7.\n\n\nGrivei, A.-C., and M. Datcu. 2018. “IGARSS 2018 - 2018 IEEE\nInternational Geoscience and Remote Sensing Symposium.” In,\n1680–83. Valencia: IEEE. https://doi.org/10.1109/IGARSS.2018.8518615.\n\n\nGuidotti, Riccardo, Anna Monreale, Salvatore Ruggieri, Franco Turini,\nFosca Giannotti, and Dino Pedreschi. 2019. “A Survey of Methods\nfor Explaining Black Box Models.” ACM Computing Surveys\n51 (5): 1–42. https://doi.org/10.1145/3236009.\n\n\nHall-Beyer, Mryka. 2017. “GLCM Texture: A Tutorial v. 3.0 March\n2017,” March. https://doi.org/10.11575/PRISM/33280.\n\n\nHuete, A. R. 1988. “A Soil-Adjusted Vegetation Index\n(SAVI).” Remote Sensing of Environment 25 (3): 295–309.\nhttps://doi.org/10.1016/0034-4257(88)90106-X.\n\n\nJiménez-Muñoz, Juan C., José A. Sobrino, Dražen Skoković, Cristian\nMattar, and Jordi Cristóbal. 2014. “Land Surface Temperature\nRetrieval Methods from Landsat-8 Thermal Infrared Sensor Data.”\nIEEE Geoscience and Remote Sensing Letters 11 (10): 1840–43. https://doi.org/10.1109/LGRS.2014.2312032.\n\n\nKaufman, Y. J., and D. Tanre. 1992. “Atmospherically Resistant\nVegetation Index (ARVI) for EOS-MODIS.” IEEE Transactions on\nGeoscience and Remote Sensing 30 (2): 261–70. https://doi.org/10.1109/36.134076.\n\n\nKupidura, Przemysław. 2019. “The Comparison of Different Methods\nof Texture Analysis for Their Efficacy for Land Use Classification in\nSatellite Imagery.” Remote Sensing 11 (10): 1233. https://doi.org/10.3390/rs11101233.\n\n\nLawrence, Rick L, and Andrea Wright. n.d. “Rule-Based\nClassification Systems Using Classification and Regression Tree (CART)\nAnalysis.” PHOTOGRAMMETRIC ENGINEERING.\n\n\nLefebvre, Antoine, Christophe Sannier, and Thomas Corpetti. 2016.\n“Monitoring Urban Areas with Sentinel-2A Data: Application to the\nUpdate of the Copernicus High Resolution Layer Imperviousness\nDegree.” Remote Sensing 8 (7): 606. https://doi.org/10.3390/rs8070606.\n\n\nLi, Jianfeng, Luyao Wang, Siqi Liu, Biao Peng, and Huping Ye. 2022.\n“An Automatic Cloud Detection Model for Sentinel-2 Imagery Based\non Google Earth Engine.” Remote Sensing Letters 13 (2):\n196–206. https://doi.org/10.1080/2150704X.2021.1988753.\n\n\nLópez-Puigdollers, Dan, Gonzalo Mateo-García, and Luis Gómez-Chova.\n2021. “Benchmarking Deep Learning Models for Cloud Detection in\nLandsat-8 and Sentinel-2 Images.” Remote Sensing 13 (5):\n992. https://doi.org/10.3390/rs13050992.\n\n\nMaes, Mikaël J. A., Abel Gonzales-Hishinuma, Ivan Haščič, Claire\nHoffmann, Alexandre Banquet, Paolo Veneri, Alexandre Bizeul, Arnau\nRisquez Martin, and Roberta Quadrelli. 2022. “Monitoring Exposure\nto Climate-Related Hazards: Indicator Methodology and Key\nResults.” Paris. https://doi.org/10.1787/da074cb6-en.\n\n\nMunyati, Christopher. 2004. “Use of Principal Component Analysis\n(PCA) of Remote Sensing Images in Wetland Change Detection on the Kafue\nFlats, Zambia.” Geocarto International 19 (3): 11–22. https://doi.org/10.1080/10106040408542313.\n\n\n“NDVI, the Foundation for Remote Sensing Phenology | u.s.\nGeological Survey.” n.d. https://www.usgs.gov/special-topics/remote-sensing-phenology/science/ndvi-foundation-remote-sensing-phenology.\n\n\nNica, Mariana, and Alexandru Gavris. 2009. “Public Policies In The\nBucharest Metropolitan Area  Inertias And Challenges For\nLocal Administation.” Proceedings of the Fifth\n\"Administration and Public Management\"\nInternational Conference: \"Public Institutions’ Capacity to\nImplement the Administrative Reform Process\", Bucharest,\nJune 23-24, 2009, Proceedings of the Fifth\n\"Administration and Public Management\"\nInternational Conference: \"Public Institutions’ Capacity to\nImplement the Administrative Reform Process\", Bucharest,\nJune 23-24, 2009,. https://ideas.repec.org//p/rom/confca/27.html.\n\n\nNistor, Constantin, Marina Vîrghileanu, Irina Cârlan, Bogdan-Andrei\nMihai, Liviu Toma, and Bogdan Olariu. 2021. “Remote Sensing-Based\nAnalysis of Urban Landscape Change in the City of Bucharest,\nRomania.” Remote Sensing 13 (12): 2323. https://doi.org/10.3390/rs13122323.\n\n\n“Normalized Difference Moisture Index | u.s. Geological\nSurvey.” n.d. https://www.usgs.gov/landsat-missions/normalized-difference-moisture-index.\n\n\nPhan, Duong Cao, Ta Hoang Trung, Van Thinh Truong, Taiga Sasagawa, Thuy\nPhuong Thi Vu, Dieu Tien Bui, Masato Hayashi, Takeo Tadono, and Kenlo\nNishida Nasahara. 2021. “First Comprehensive Quantification of\nAnnual Land Use/Cover from 1990 to 2020 Across Mainland Vietnam.”\nScientific Reports 11 (1): 9979. https://doi.org/10.1038/s41598-021-89034-5.\n\n\nProbst, Philipp, Marvin N. Wright, and Anne-Laure Boulesteix. 2019.\n“Hyperparameters and Tuning Strategies for Random Forest.”\nWIREs Data Mining and Knowledge Discovery 9 (3): e1301. https://doi.org/10.1002/widm.1301.\n\n\nQi, J., A. Chehbouni, A. R. Huete, Y. H. Kerr, and S. Sorooshian. 1994.\n“A Modified Soil Adjusted Vegetation Index.” Remote\nSensing of Environment 48 (2): 119–26. https://doi.org/10.1016/0034-4257(94)90134-1.\n\n\nReddy, R. S., S. Thayalan, C. R. Shiva Prasad, P. S. A. Reddy, and J. L.\nSehgal. 1990. “Utility of Satellite Data for Land Evaluation in\nLand Use Planning for a Part of Northern Karnataka.” Journal\nof the Indian Society of Remote Sensing 18 (4): 34–44. https://doi.org/10.1007/BF02997071.\n\n\nSavin, Elena, and Cristian Flueraru. 2006. “Use of Vegetation NDVI\nTime Series for Drought Monitoring in Romania.”\n\n\nSchulte to Bühne, Henrike, and Nathalie Pettorelli. 2018. “Better\nTogether: Integrating and Fusing Multispectral and Radar Satellite\nImagery to Inform Biodiversity Monitoring, Ecological Research and\nConservation Science.” Methods in Ecology and Evolution\n9 (4): 849–65. https://doi.org/10.1111/2041-210X.12942.\n\n\nSegal-Rozenhaimer, Michal, Alan Li, Kamalika Das, and Ved Chirayath.\n2020. “Cloud Detection Algorithm for Multi-Modal Satellite Imagery\nUsing Convolutional Neural-Networks (CNN).” Remote Sensing of\nEnvironment 237 (February): 111446. https://doi.org/10.1016/j.rse.2019.111446.\n\n\nSilveira, Eduarda M. O., Sérgio Henrique G. Silva, Fausto W.\nAcerbi-Junior, Mônica C. Carvalho, Luis Marcelo T. Carvalho, Jose\nRoberto S. Scolforo, and Michael A. Wulder. 2019. “Object-Based\nRandom Forest Modelling of Aboveground Forest Biomass Outperforms a\nPixel-Based Approach in a Heterogeneous and Mountain Tropical\nEnvironment.” International Journal of Applied Earth\nObservation and Geoinformation 78 (June): 175–88. https://doi.org/10.1016/j.jag.2019.02.004.\n\n\nSun, Weiwei, Bo Du, and Shaolong Xiong. 2017. “Quantifying\nSub-Pixel Surface Water Coverage in Urban Environments Using Low-Albedo\nFraction from Landsat Imagery.” Remote Sensing 9 (5):\n428. https://doi.org/10.3390/rs9050428.\n\n\nTang, Cheng, Damien Garreau, and Ulrike von Luxburg. 2018. “When\nDo Random Forests Fail?” In. Vol. 31. Curran Associates, Inc. https://proceedings.neurips.cc/paper/2018/hash/204da255aea2cd4a75ace6018fad6b4d-Abstract.html.\n\n\nYuan, Karen, Patrick O’Neil, and Diego Torrejon. 2020. “8 -\nLandsat’s Past Paves the Way for Data Democratization in Earth\nScience.” In, edited by Feras A. Batarseh and Ruixin Yang,\n147–61. Academic Press. https://doi.org/10.1016/B978-0-12-818366-3.00008-3.\n\n\nZhu, Zhe, and Curtis E. Woodcock. 2014. “Automated Cloud, Cloud\nShadow, and Snow Detection in Multitemporal Landsat Data: An Algorithm\nDesigned Specifically for Monitoring Land Cover Change.”\nRemote Sensing of Environment 152 (September): 217–34. https://doi.org/10.1016/j.rse.2014.06.012."
  },
  {
    "objectID": "abbreviations.html",
    "href": "abbreviations.html",
    "title": "Common Remote Sensing Abbreviations!",
    "section": "",
    "text": "As remote sensing can get quite complex in terms of nomenclature, this abbreviation index can come in handy when potential concept explanations are not clear!\n\nRBG : Red, Blue Green\nTOA : Top of Atmosphere\nL-8 : Landsat-8 Satellite\nS-2 : Sentinel-2\nGEE : Google Earth Engine\nSNAP : Sentinel Application Platform is provided by the ESA/ESRIN and allows the Earth Observation Community with a free tool to process and analyse satellite imagery. It has the advantage of providing InSAR Processing capabilities, which is not yet the case with GEE\nPOI : Points of Interest - these are points that are representative of certain land-cover types and allows for comparison between platforms. This was for example used in the Bucharest Analysis where we used reference area for water, green area and industrial area to compare L-8 and S-2 imagery.\nESA : European Space Agency\nESRIN : ESA center for earth Observation created in 1966 and currently based in Frascati, Italy\nSWIR : Short-wave infrared, part of the electromagnetic spectrum and allows for identification of objects invisible to the human eye and traditional multi-spectral bands. It can allow for the identification of certain terrain characteristics (i.e. certain bands in SWIR is more highly absorbed by water bodies). Ranges from 1.4 to 3 µm (micrometers)\nNIR : Near infra-red\nDOS : Dark Object Subtraction - Method to correct raw satellite imagery by considering the true value of the darkest pixel in the image as 0. If this is not the value of said pixel, this is attributed to variations caused by the atmosphere\nNDVI : Normalised Difference Vegetation Index - Index determining the density of live vegetation in a particular area. The formula for this is: \\[NDVI= \\frac{NIR-Red}{NIR+Red}= \\frac{Landsat B5 - Landsat B4} {Landsat B5 + Landsat B4}\\] The values range between -1 and 1: 0.1 and below considered low values, between 0.2 and 0.5 moderate values (i.e. shrubs and grass-land) and high values between 0.6 and 0.9 (typically dense vegetation, forests, fertile crops) “NDVI, the Foundation for Remote Sensing Phenology | u.s. Geological Survey” (n.d.)\nNDMI : Normalised Difference Moisture Index - Similar methodology and interpretation to NDVI but here determines vegetation water content “Normalized Difference Moisture Index | u.s. Geological Survey” (n.d.) . For Landsat 8-9, the formula is as follows: \\[NDMI= \\frac{NIR-SWIR}{NIR+SWIR}= \\frac{Landsat B5 - Landsat B6} {Landsat B5 + Landsat B6}\\]\nIFOV : Instantaneous Field of View\nSAR : Synthetic Aperture Radar\nNadir : celestial sphere directly below an observer\nAzimuth : the direction of a celestial object from the observer, calculated through distance from horizon from a cardinal point (usually north or south)\nPCA : Principal Component Analysis - is a method of unsupervised learning which aims to reduce the number of dimensions whilst still keeping most of the information. In remote sensing this is particularly useful as it can help understand and visualise where changes in terrain characteristics have taken place ( Munyati (2004) )\nGLCM : gray-level co-occurrence matrix which is a method that examines textures whilst considering the spatial relationship of the pixels. Several different methods can be applied which prioritize different pixel characteristics (i.e. homogeneity, contrasts etc.)\nGAUL : Global Administrative Unit Layers - unique name and code for all administrative area globally, with level 1 for countries and lower levels for more granular breakdowns. This initiative was started by the FOA (Food and Agriculture Organization) and now used open-access in GEE.\nCART : Classifications and Regression trees which compromises of\n\nclassification methods: method for mapping binary decisions that lead to a decision about the class (interpretation) of an object\nregression methods: modelling relationship between one or mode variables in a linear manner\n\nLULC : Land-Use Land-Cover - indicates the visible surface of land whist also indicating the socio-economic dimension (e.g. forestry, agriculture, residential etc.). In order for successful understanding of this tool, is it important to have data availability in order to show how these evolve over time, they are time sensitive ( Phan et al. (2021) )\n\n\n\n\n\nMunyati, Christopher. 2004. “Use of Principal Component Analysis (PCA) of Remote Sensing Images in Wetland Change Detection on the Kafue Flats, Zambia.” Geocarto International 19 (3): 11–22. https://doi.org/10.1080/10106040408542313.\n\n\n“NDVI, the Foundation for Remote Sensing Phenology | u.s. Geological Survey.” n.d. https://www.usgs.gov/special-topics/remote-sensing-phenology/science/ndvi-foundation-remote-sensing-phenology.\n\n\n“Normalized Difference Moisture Index | u.s. Geological Survey.” n.d. https://www.usgs.gov/landsat-missions/normalized-difference-moisture-index.\n\n\nPhan, Duong Cao, Ta Hoang Trung, Van Thinh Truong, Taiga Sasagawa, Thuy Phuong Thi Vu, Dieu Tien Bui, Masato Hayashi, Takeo Tadono, and Kenlo Nishida Nasahara. 2021. “First Comprehensive Quantification of Annual Land Use/Cover from 1990 to 2020 Across Mainland Vietnam.” Scientific Reports 11 (1): 9979. https://doi.org/10.1038/s41598-021-89034-5."
  },
  {
    "objectID": "intro.html#understanding-the-differences-between-s-2-and-l-8",
    "href": "intro.html#understanding-the-differences-between-s-2-and-l-8",
    "title": "Introducing Remote Sensing - A Bucharest Analysis",
    "section": "Understanding the differences between S-2 and L-8",
    "text": "Understanding the differences between S-2 and L-8\nNow that we have images from both sources, we proceed to re-sample the images to the same resolution. Below we have a comparison of the bands between Sentinel-2 and Landsat-8.\n\n\nComparison of Sentinel and Landsat Bands, taken from López-Puigdollers, Mateo-García, and Gómez-Chova (2021)\n\n\nYet this is not enough as in order to make cross-platform comparisons successful! Below we have a detailed overview comparing band resolution between Sentinel and Landsat, with respective links to sources of Table 1 (left) and Table 2 (right)!\n\n\n\nSentinel-2 (left) and Landsat-8 (right) band comparisons\n\n\n\nWe see that the two platforms share certain similar characteristics, but differences are notable. For example, even if the Blue, Green and Red Channels are present on both, their wavelengths do not overlap perfectly. Furthermore, both platforms do not have all the same bands, with 1,2,3,4 overlapping similarly and B11 and B12 on S-2 working with B6 and B7 on L-8. In our application today, we will only be using Bands 2 to 4 on both, B6 and 7 on Landsat and B8 and 12 on Sentinel.\nMost importantly, these two platforms do not share the same resolutions, with L-8 principally outputting at 30m compared to S-2 between 10, 20 or 60m.\nTo overcome this, we upscale the Sentinel Imagery to Fit the 30m resolution displayed by Landsat. As we decide to focus on Bucharest specifically, we also subset the image to only the city outline using shapefiles provided by GADM. The clipped results are as follows:\n\n\n\n\nSentinel-2 (left) and Landsat-8 (right) clipped RBG images of Bucharest (at same resolution)\n\n\n\nSelecting our Points of Interest\nNow that we have our clipped view of Bucharest, we select 3 POI’s which are Green Area (Pădurea Băneasa), Water (the Morii lake) and Industrial Area (Industriilor Sector). With these representations that serve as a landmark, we will be able to make comparisons between L-8 and S-2 data.\n\n\n1. Green Area, 2. Water, 3. Industrial Area\n\n\nComputational Analysis of L-8 and S-2 Images\nNow that we have our reference POI’s in place, we were able to input this data in RStudio and analyse the spectral signatures. We acknowledged beforehand that both of these sensors had a dozen bands each, but in this case, we only kept 4 overlapping bands, which are Blue, Green and Red (B2, B3 and B4) and SWIR (B12 on S-2 and B7 on L-8).\nOur results are presented below, with bands 1, 2, 3 and 4 representing Blue, Green, Red and SWIR:\n\n\nComparison of Band Values, A and B showing S-2 and C and D are L-8 results\n\n\nWith the above image, we get an overview of the different bands that coincide between L-8 and S-2 when analysing our POI’s. Our green line, which represents the green areas in Bucharest Urban area, shows similar trends between L-8 and S-2. The same if true for industrial and water areas, showing that the bands between L-8 and S-2 react similarly. Furthermore, the density plots are also encouraging as they have the same shapes and similar reactions to the various POI’s. Nonetheless, even if the bands follow similar movement, we acknowledge that the values are not the same. For example, the average band water for the grassy area is around 1500 for S-2 whereas this value is at 2500 for the same area in L-8.\nIt is interesting to note that the Water POI has the least variation in band values, with the highest pixel density in both platforms. This is followed by the grassy area. Finally, the industrial area has greater spread of band values.\nIt is not surprising that the industrial area had the most variation as, not only was our initial POI Shape 3 had a little overlap over water areas, but also had the least uniformity in content (aka not purely industrial areas but included houses, roads etc.). Urban areas are known to have more variation in band values ( Lefebvre, Sannier, and Corpetti (2016) ). This also explains why the confidence intervals in the industrial area are much broader than for the other two categories."
  },
  {
    "objectID": "corrections.html",
    "href": "corrections.html",
    "title": "Atmospheric Corrections",
    "section": "",
    "text": "Collecting and merging raster images\nFor this topic, we decide to analyse the whole of Tasmania. Tasmania is has a landmass of over \\(68,000 km^2\\). A cloud-clear Landsat Image provides overview on approximately \\(34,000km^2\\) which means that several captures are necessary. Below is an example of a single image over Tasmania, not enough to be representative of the island as a whole. We need to merge several to create a mosaic. Below we use these 7 panes and put them in a mosaic to create a full RBG view of the Island\nWe took our images from the USGS and used 7 images in total to cover the whole Island. Of these 7 images, 5 came from Landsat 8 and 2 from Landsat 9. Six of the frames were taken between 24th and 28th of January 2022 and one of them was on the 12th of February 2022. We deemed this temporal difference between images not to be significant but we will be analysing the implications further down.\nThe bands presented here are at 30m resolution. We omit bands 8 (15m), 10 and 11 (100m) as they have different resolutions (refresher table available here). As the information that spectral bands can provide is high, we can use this to get additional insight on our area of study!\nAs Tasmania is known as an important microcosm, home to many endemic species both of animals and vegetation, we look at at vegetation measures. Using NIR and Red bands in L-8/9 we can understand vegetation intensity across the island. The below panel illustrates which areas meet different thresholds of NDVI:\nWe see that a great proportion of Tasmanian Landmass has positive levels of NDVI, which would indicate that there are little to no areas of barren rocky or sandy surfaces (US Geological Society). This is not surprising as over 50% of Tasmania’s land area has some form of reservation classification.\nTo continue understanding the Tasmania’s composition, we also focus on the moisture index. NDMI is used to determine vegetation water content and is measured similarly to NDVI. Below we have a similar breakdown of the different areas across various thresholds:\nAs expected, the land areas have overwhelmingly positive values! In addition we have to keep in mind the temporal aspect as these observations were taken in the southern Hemisphere summer which means these values are likely to be higher during the traditionally wetter seasons of June, July and August (source)\nThe principal issue encountered for this analysis came in using the 'Rtools' and 'RStoolbox' packages. Indeed, different dependencies and technical differences (Mac vs Windows and R version 4.2.2 and 4.2.1) made using them difficult, specifically the 'rasterPCA' function.\nThis allowed me to gain better understanding of library development as I had to use the source code for the specific PCA function (master code here) and then download the appropriate objects as internal functions (here). We thank Benjamin Leutner for developing the packages and making the source code available. With this difficulty, I was able to dive deeper into the working of computing for corrections in Remote Sensing.\nAs for corrections in general, I was unfamiliar with this topic before but found it rewarding and insightful. The amount of information possible to extract from raw spectral data is impressive and is something I want to explore further. Although we only used NDVI and NDMI in this analysis, we have more options which could include:\nAlso interesting to see how the democratisation of data availability in remote sensing paired with technological has allowed for facilitated research on earth’s surface (Schulte to Bühne and Pettorelli (2018) ) . For example, the Landsat programme which has been running since 1972 gives the ability to see how methods change over time ( Yuan, O’Neil, and Torrejon (2020) ). These technological advances are important in correction with examples such as machine learning using Convolutional Neural Networks (CNN) to automatically identify the presence of clouds in images ( Segal-Rozenhaimer et al. (2020) ).\nFinally, the same is true for texture analysis. In our Tasmanian Analysis, we only focused on grey level co-occurrence matrix to use in the process of land use/cover classification. We could aim to use other methods in future analyses such as Laplace filters and granulometric analysis ( Kupidura (2019) )"
  },
  {
    "objectID": "2_sensor_presentation.html",
    "href": "2_sensor_presentation.html",
    "title": "Presenting a Sensor: Sentinel 6A and the Poseidon-4 Radar Altimeter",
    "section": "",
    "text": "For this part of the project, another platform was used: Xaringan\nThis new platform allows for the creation of Slides through R! This is a first attempt at using this type of slides and has the ability of being embedded directly into our Quarto blog!! (At the cost of some interactivity and lost formats..)\n\n\n\n\n\n\n\n\nThis is a really efficient way of sharing the slides, even if we can recognise certain issues regarding readability and usability. Indeed, we see that when we scroll down the webpage over the presentation, the slides are not always easy to control and tend to go by too quickly! To overcome this, the user must click on the presentation and use the left and right arrows to navigate through the presentation in a more controlled manner!\nFor full screen presentation of these slides, they are available here! (link opens in new tab)\n\n\n\n \n\n      \n         Introducing Remote Sensing - A Bucharest Analysis\n                \n  \n  \n      \n        Atmospheric Corrections"
  },
  {
    "objectID": "corrections.html#texture-and-filtering",
    "href": "corrections.html#texture-and-filtering",
    "title": "Atmospheric Corrections",
    "section": "Texture and Filtering",
    "text": "Texture and Filtering"
  },
  {
    "objectID": "corrections.html#finding-clusters-and-common-characteristics",
    "href": "corrections.html#finding-clusters-and-common-characteristics",
    "title": "Atmospheric Corrections",
    "section": "Finding Clusters and common characteristics",
    "text": "Finding Clusters and common characteristics\nWe now proceed to look at Principal Component Analysis (PCA) which aims to reduce the dimensionality in texture bands and provide easier understanding of the environmental information, whilst preserving most of the information. So it has the benefit of providing clear overviews of changes, such as variations of terrain characteristics.\n\n\n\n\n\n   \n    Component 1 \n    Component 2 \n    Component 3 \n    Component 4 \n    Component 5 \n    Component 6 \n    Component 7 \n    Component 8 \n    Component 9 \n  \n\n\n Standard deviation \n    2.5547583 \n    1.1690118 \n    0.7963765 \n    0.5411714 \n    0.3271707 \n    0.2268870 \n    0.0996739 \n    0.0921788 \n    0.0508813 \n  \n\n Proportion of Variance \n    0.7251989 \n    0.1518432 \n    0.0704684 \n    0.0325407 \n    0.0118934 \n    0.0057197 \n    0.0011039 \n    0.0009441 \n    0.0002877 \n  \n\n Cumulative Proportion \n    0.7251989 \n    0.8770421 \n    0.9475105 \n    0.9800512 \n    0.9919446 \n    0.9976644 \n    0.9987682 \n    0.9997123 \n    1.0000000 \n  \n\n\n\n\nAs the above table provides information regarding numerical information, we can get a better understanding of how spectral data of Tasmanian L-8 imagery (during the summer season or 2022) varies. We identify that over 98% of the spectral variance is contained within the first 4 clusters. Using PCA in remote sensing provides several advantages as it allows to visualise the changes that occurred in a certain area ( Munyati (2004) ) and reduce the dimensionality of the spectral data ( Balázs et al. (2018) ). This may be difficult to interpret numerically, therefore we include visualisation of the top 4 components in the image below:\n\n\nIllustration of top 4 PCA bands for our study area"
  },
  {
    "objectID": "corrections.html#differences-between-panes",
    "href": "corrections.html#differences-between-panes",
    "title": "Atmospheric Corrections",
    "section": "Differences between panes",
    "text": "Differences between panes\nWe note that in our initial image, with the 7 panes, there are temporal differences between when each of them were captured, especially one of them taken more than two weeks later (top left). Not only is it taken later, but we also see the strong presence of clouds (i.e. Band 9 top left and visually with the white areas). Below we have the same mosaic but instead keep only 6 panes which were taken within 4 days of each other:\n\n\nMosaic without temporal outlier\n\n\nWe add this difference for visibility but also to show that time and cloud cover are very important aspect and can influence image results. In our case, even if the differences are visible in the later image, we will continue will all 7 in our analysis below to get a full idea of the island, even if the results may not be perfectly precise."
  },
  {
    "objectID": "corrections.html#texture",
    "href": "corrections.html#texture",
    "title": "Atmospheric Corrections",
    "section": "Texture",
    "text": "Texture\nWe use filtering on our images to reduce the computational weight of the image and make it easier for processing in the below texture analysis.\nWe use the Gray level co-occurrence matrix (GLCM) to understand how different regions are characterised. It considers spatial relationships between pixels simultaneously to understand how the textures compare between areas of the mosaic.\n\n\nNIR Band Texture\n\n\nWith this panel, we are able to start visualising different terrain characteristics. The different categories indicate what characteristics are focused on between analysed neighbouring pixels.\nFor example, the ‘contrast’ pane emphasises areas with high contrast between neighbouring pixels, which in this case has value in the upper center part of the island. Which makes sense as Hobart, the capital of Tasmania, is in that area and there would be contrast between urban and forests for example. As for another value such as ‘homogeneity’, the values are higher towards the center of the island which is the least urbanised, thus having most similar surroundings, mainly covered by forests ( Hall-Beyer (2017) and additional breakdowns of the characteristics starting page 29)."
  },
  {
    "objectID": "GEE_intro.html#exploring-the-examples-in-the-script-editor",
    "href": "GEE_intro.html#exploring-the-examples-in-the-script-editor",
    "title": "Introduction to Google Earth Engine",
    "section": "Exploring the Examples in the script editor",
    "text": "Exploring the Examples in the script editor\nThe interface is easy to use and provides a panoply of different scripts to get accustomed to the different uses of the platform.\nLearning to use Javascript - JavaScript (JS) is a scripting/programming language which allows for the implementation of dynamic behaviour and updating control multimedia. In our case, we use JavaScript to use the GEE API and access their satellite imagery data and analysis capabilities (GEE platform)."
  },
  {
    "objectID": "GEE_intro.html#exploring-paris-with-gee",
    "href": "GEE_intro.html#exploring-paris-with-gee",
    "title": "Introduction to Google Earth Engine",
    "section": "Exploring Paris with GEE",
    "text": "Exploring Paris with GEE\nWe start by playing around with the Earth Engine to get a better idea and understanding of what tools are available to us. Our aim is to analyse Paris and it’s characteristics so we start off by taking the appropriate shapefile ('GID_2 == \"FRA.8.3_1\"') from GADM.\nThe images we use are from L-8 and Level 2, Collection 2 tier 1 images (additional info on L-8 tiers here). They were collected between June 2020 and October 2022.\nAfter being able to clip the city as a whole, we compare the images:\n\nLeft image shows Clipped Paris untouched (aka without any transformations). We see that the image is mostly black as no correction has been made\nRight Image shows Paris with the appropriate adjustment for surface reflectance through scaling factors\n\n\n\n\n\nInitial clip of Paris, including not transformed (left) and adjusted for surface reflectance (right)"
  },
  {
    "objectID": "GEE_intro.html#taking-the-analysis-further",
    "href": "GEE_intro.html#taking-the-analysis-further",
    "title": "Introduction to Google Earth Engine",
    "section": "Taking the Analysis further",
    "text": "Taking the Analysis further\nTexture Analysis in GEE\nSimilar to one of our previous analyses, we choose to look at Gray Level Co-Occurrence Matrix (GLCM), a texture analysis which considers the spatial relationships of pixels in an image. Below, we include the contrast GCLM, which uses the contrast between neighbouring pixels as a measure of the texture.\n\n\nContrast GLCM\n\n\nAs a sanity check, we interpret the results from the image:\n\nLow Contrast at points in group 1 as these are the park areas of Paris (‘bois de Vincennes’ on the right and ‘hippodrome de Long-champs’ on the left). Due to low contrast, the GCLM does not indicate much texture change in the area, which is expected as they are all park/woodland areas\nHigh contrast at point 2, as this is the cultural and touristic center, notably including the Eiffel tower, small parks, Haussmannian 19th century buildings and recently built elements. So it is not a surprise that this area has high contrast values.\nFinally, area 3 follows part of the Seine. As this is the main water body in the city, we would expect high values of similarity which is is the case as there are many light pixels grouped together in that area!\nPCA in GEE\nAlthough not as intuitive as the rasterPCA in RStoolbox, PCA analysis is possible in GEE. we find that the first 4 clusters account for more than 98% of the total variance of the studied area.\n\n\nValues of PCA clusters (in %)\n\n\nBelow we have an illustration of the four main groups visible. We see that a great deal of the variance is captured in the first frame. This is not a surprise as Paris is an Urban area and has quite strong similarities in terms of colours, and does not have a lot of variance with big contrasts between urban and green areas for example (parks are quite small compared to other cities, say London).\n\n\nBand Maths\nNDVI\nThe Normalised Vegetation Index is the usual indicator of vegetation in an area. Here it makes sense that the values are higher in the park areas, closer to the outskirts of the city, than in the center which has a very high population density.\n\n\nThe Normalised Vegetation Index\n\n\nNDMI\nThe Normalised Moisture Index allows to collect information on the amount of moisture in the soil. The bands are calculated as follows in GEE:\n\nvar NDMI = clip.select('SR_B5').subtract(clip.select('SR_B6'))\n  .divide(clip.select('SR_B5').add(clip.select('SR_B6')))\n\nThe values go from -1 to 1, with the brown areas having the highest positive values. Again, most of the values are around 0 as the city has high building density. Nonetheless, the parks have high moisture value, with a strong brown colour.\n\n\nThe Normalised Moisture Index\n\n\nGCI\nThe Green Chlorophyll Index is an index that we have not analysed before but mentioned before. We thought using it in this project would be interesting to see the results but also it’s implementation in GEE. It was initially used in for MODIS ( Gitelson, Kaufman, and Merzlyak (1996) ) but as bands have similar characteristics between platforms, it can also be used on L-8.\n\nvar GCI = clip.select('SR_B5').divide(clip.select('SR_B5').add(1))\n\nBelow we have the illustration of the GCI. The values range between -1 and 1, with bright red representing a value of 1. In the case of Paris, we see that the values are mainly pinkish, representative of an urban environment, which is to be expected in Paris.\n\n\nThe Green Chlorophyll Index"
  },
  {
    "objectID": "GEE_intro.html",
    "href": "GEE_intro.html",
    "title": "Introduction to Google Earth Engine",
    "section": "",
    "text": "Taking the Analysis further\nUsing GEE was eye-opening, seeing how efficient getting access to satellite imagery was compared to using SNAP and other sources such as Copernicus Open Access Hub (for S-2) and Earth Explorer (for L-8).\nThis initial project was a very good opportunity to start getting accustomed to using JS and putting into practice. Although, I did not use much of my own code for this week (majoritarily inspired from CASA0023 and web-sources), I was still able to understand local areas and tweak the code accordingly! I was also able to build on the band math, using indices such as NDMI as my understanding of Javascript and Bands has improved.\nI was able to also make my findings more interactive by embedding my PCA results in a Google Slide presentation. This was done using raw HTML and ‘iframe’ directly.\nThis was a very plentiful diary entry, as it has given me many ideas but also shown me the GEE has many options which I want to look into. Notably looking at the evolution of areas over time, with examples in mind aiming to show how global warming, droughts and overconsumption have let to considerable changes in water levels in certain areas (i.e. lake, reservoir, damn etc.)\nOne striking example that inspired me was looking at the evolution of Las Vegas over the years, through its unwelcoming climate setting (i.e. in the desert) but which still witnessed considerable growth over the past half century."
  },
  {
    "objectID": "correction_GEE_1.html",
    "href": "correction_GEE_1.html",
    "title": "Corrections in GEE - 1",
    "section": "",
    "text": "Setting the area in GEE\nWe start of our analysis by getting a simple view of the studied area. Here, we have Wollongong illustrated through S-2 with images collected between January and October 2022. In this case, we selected images with less than 1% cloud cover, which allows up to not need to implement a cloud mask but provide a clear image of the area:\nWhilst this method allows for clear images, when studying an area these might not always be available. For example, the study area might not have sufficient low cloud-cover images as the research is time specific (i.e. focused on a specific time period). For this reason, the below image is the result we have when include images with up to 20% cloud cover:"
  },
  {
    "objectID": "correction_GEE_1.html#understanding-how-the-cloud-mask-works",
    "href": "correction_GEE_1.html#understanding-how-the-cloud-mask-works",
    "title": "Corrections in GEE - Part 1",
    "section": "Understanding how the cloud mask works",
    "text": "Understanding how the cloud mask works\nThe urban area of Wollongong is particularly covered in clouds, so-much so that none of the urban area is visible. To counter this, we use a cloud mask which uses the QA60 band, where the QA stands for ‘Quality Assurance’ and 60 refers to the granularity of the image, with 60m spatial resolution source. It has two possible values, bit 10 and bit 11 which respectively to opaque and cirrus clouds. Using this band has been particularly successful in developing automatic cloud models for S-2 in GEE ( Li et al. (2022) ).\nIn addition to the mask, we take the median value of the pixel and apply it as a value. This allows the removal of the clouds whilst also keeping the image information.\nNOTE: we acknowledge that other methods which are more efficient exist, as some information is lost with the ‘median’ method. We attempted to use a GEE community provided example of s2cloudless but was unsuccessful as we recurring memory limit issues.\nWhen applying the respective cloud masking function, we get the following result:\n\n\n\nSuccessful Cloud Masking Output\n\n\nWe see a significant improvement in the results, with no more clouds appearing in the image. The polygons included above serve as reference areas for the classifications we with to use.\nThe colours refer to:\n\n\n\nPolygon Index"
  },
  {
    "objectID": "correction_GEE_1.html#understanding-how-cloud-mask-works",
    "href": "correction_GEE_1.html#understanding-how-cloud-mask-works",
    "title": "Corrections in GEE - 1",
    "section": "Understanding how cloud mask works",
    "text": "Understanding how cloud mask works\nThe urban area of Wollongong is particularly covered in clouds, so-much so that none of the urban area is visible. To counter this, we use a cloud mask which uses the QA60 band, where the QA stands for ‘Quality Assurance’ and 60 refers to the granularity of the image, with 60m spatial resolution source. It has two possible values, bit 10 and bit 11 which respectively to opaque and cirrus clouds. Using this band has been particularly successful in developing automatic cloud models for S-2 in GEE ( Li et al. (2022) ).\nIn addition to the mask, we take the median value of the pixel and apply it as a value. This allows the removal of the clouds whilst also keeping the image information.\nNOTE: we acknowledge that other methods which are more efficient exist, as some information is lost with the ‘median’ method. We attempted to use a GEE community provided example of s2cloudless but was unsuccessful as we recurring memory limit issues.\nWhen applying the respective cloud masking function, we get the following result:\n\n\nSuccessful Cloud Masking Output\n\n\nWe see a significant improvement in the results, with no more clouds appearing in the image. The polygons included above serve as reference areas for the classifications we with to use.\nThe colours refer to:\n\n\nPolygon Index"
  },
  {
    "objectID": "correction_GEE_1.html#random-forest---at-polygon-level",
    "href": "correction_GEE_1.html#random-forest---at-polygon-level",
    "title": "Corrections in GEE - Part 1",
    "section": "Random Forest - at polygon level",
    "text": "Random Forest - at polygon level\nBy selecting the reference area polygons, we use this as ground truths in classifier models. These serve as reference areas by which our Random-forest will predict in which category areas outside our reference polygons belong:\n\n\n\nRandom Forest Classification of Wollongong ground areas\n\n\nHere, 70% of the data is in the training set, and 30% in the test. This means that 70% of the data is seen by the model, and then once the parameters are created, it tests it’s efficiency on the remaining 30%, which remain unseen at that point.\nIn this case and all following classification analysis, ‘grey’, ‘blue’, ‘white’, ‘black’, ‘green’ are respectively urban low, water, high urban, farmland and forest areas!"
  },
  {
    "objectID": "correction_GEE_1.html#at-pixel-level",
    "href": "correction_GEE_1.html#at-pixel-level",
    "title": "Corrections in GEE - Part 1",
    "section": "At pixel level",
    "text": "At pixel level"
  },
  {
    "objectID": "correction_GEE_1.html#random-forest-rf",
    "href": "correction_GEE_1.html#random-forest-rf",
    "title": "Corrections in GEE - 1",
    "section": "Random Forest (RF)",
    "text": "Random Forest (RF)\nAt polygon level\nBy selecting the reference area polygons, we use this as ground truths in classifier models. These serve as reference areas by which our Random-forest will predict in which category areas outside our reference polygons belong:\n\n\nRandom Forest Classification of Wollongong ground areas\n\n\nHere, 70% of the data is in the training set, and 30% in the test. This means that 70% of the data is seen by the model, and then once the parameters are created, it tests it’s efficiency on the remaining 30%, which remain unseen at that point.\nIn this case and all following classification analysis, ‘grey’, ‘blue’, ‘white’, ‘black’, ‘green’ are respectively urban low, water, high urban, farmland and forest areas!\nAt pixel level\nAs the previous analysis was conducted at polygon, some accuracy is lost as it is not as representative as taking it at pixel level. We decide to follow with this as it has the advantage of generally being more precise in most cases, especially urban areas. Although, this is not always the case, as heterogeneous or mountain tropical environments have had evidence where they perform better with object based modelling ( Silveira et al. (2019) ). We will compared the visual and numeric results from both classification approach methods:\n\n\nPixel Classification Approach\n\n\nWe see that the Pixel Classification approach is more precise that the Object based approach. Notable as the pixel based approach is more successful in categorising Farm Land areas (the black dots) which were in-existent in the object based approach."
  },
  {
    "objectID": "correction_GEE_1.html#cart-classification-and-regression-tree",
    "href": "correction_GEE_1.html#cart-classification-and-regression-tree",
    "title": "Corrections in GEE - 1",
    "section": "CART (Classification and Regression Tree)",
    "text": "CART (Classification and Regression Tree)\nWe then proceed to run the same analysis for CART. We use the same methods as above for polygon and pixel level, putting 70% of the data in training and 30% in test. It has the advantage of automatically selecting the useful spectral data ( Lawrence and Wright (n.d.) ), making it easy to work with even for non-ML experts.\nLike for the RF, we initially use 10 nodes, meaning using trees with a maximum of 10 leaf nodes. These trees look something a little like this:\n\n\nExample of how nodes in CART work\n\n\nThese create a decision tree, which typically start with a single node, and branches out into the different possible outcomes. By selecting 10 or 100 nodes, the algorithm creates these branches according to different arguments, thus influencing and changing the results.\nAt polygon level\nOur initial Cart output illustrates the model with object based references with 10 nodes.\n\n\nCART polygon 10 nodes\n\n\nWe proceed to see how the results change when we add more granularity in the number of possible nodes, increasing this to 100.\n\n\nCART polygon 100 nodes\n\n\nDifferences are visible between the different nodes in the object based analysis. Similar to the RF, there seems to be no black classification (farm land). This is likely due to the non-optimal reference area selecting by us, the user. Our farm-land area most likely encompasses too many topographical differences within the polygon, which does not allow for precise identification of farm-land through object based classification.\nNonetheless, pixel level analysis allows us to make different insights\nAt pixel level\n\n\nCART pixels 10 nodes\n\n\nWith 10 nodes at pixel level, we already see the appearance of the black dots, or representations of the farm-land categories. We increase the number of nodes to 100 to see if this betters the results.\n\n\nCart pixels 100 nodes\n\n\nThe classifications change depending on the number of nodes but we can not visually determine which method is best.\nWe can do this numerically by comparing the training and validation accuracy between RF and CART for our study area Wollongong:\n\n\n\n\n\n   \n    Training Accuracy \n    Validation Accuracy \n  \n\n\n Random Forest \n    0.9951065 \n    0.8132372 \n  \n\n CART (10 nodes) \n    0.7927461 \n    0.7916121 \n  \n\n CART (100 nodes) \n    0.8428325 \n    0.7876802 \n  \n\n\n\n\nWe see that RF has the highest validation accuracy although it seems to have considerable over-fitting, with the accuracy decreasing by nearly 20% between training and validations sets. This is not surprising as RF’s tend to over-fit, and this is further accentuated by our non-optimal reference object choices ( Tang, Garreau, and Luxburg (2018) )."
  },
  {
    "objectID": "correction_GEE_1.html#correction-analysis-methods",
    "href": "correction_GEE_1.html#correction-analysis-methods",
    "title": "Corrections in GEE - 1",
    "section": "Correction Analysis methods",
    "text": "Correction Analysis methods\nThis entry was quite insightful in terms of technical understanding in remote sensing image processing and correction. Notably introducing ML techniques that are CART and RF’s. The insights found were interesting, especially with the models correctly identifying various ground characteristics, such as the rivers which coincide with the existing topography.\nIt was interesting to compare these different techniques, playing around with the different techniques (RF vs CART) but also looking at various parameters such as the number of nodes and reference methods (object based vs pixel).\nIn future, now that we are more familiar with the methods, we look into getting more precise models. We would do so by paying attention to the hyper-parameters tuning strategies in order to optimise the outcomes ( Probst, Wright, and Boulesteix (2019) ) whilst still keeping it computationally efficient. This includes, but not limited to:\n\nminimum number of samples a node must contain\nmaximum number of nodes per branch\ndefining a splitting rule (which optimises Gini Impurity in classification, determining how a feature should split the data when forming the tree)\n\nFinally, we also acknowledge the black box elements to these statistical methods used for analysis. Black boxes are systems that their internal logic to the user ( Guidotti et al. (2019) ) which make certain results, although correct, difficult to precisely explain."
  },
  {
    "objectID": "correction_GEE_1.html#gee-technicalities",
    "href": "correction_GEE_1.html#gee-technicalities",
    "title": "Corrections in GEE - 1",
    "section": "GEE Technicalities",
    "text": "GEE Technicalities\nThis entry allowed to further delve into the technical side of GEE.\nInitially, we managed to clip the relevant area from the GAUL data set and user forums. This is interesting as we used the clip directly when defining the mask instead of clipping the image separately. The JS code format is as follows:\n\nvar waytwo = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n                  .filterDate('2022-01-01', '2022-10-31')\n                  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',20))\n                  .map(maskS2clouds)\n                  // clips the images and applies it over the image collection\n                  .map(function(image){return image.clip(wollo)});\n\nIssues were encountered when trying to understand how to make the CART model for classification work. When running the above code, although we managed to clip the image an create the wished layer, we could not get the input to work when getting the cart model. We got the below error:\n\n\nClip Error Example - GEE Console\n\n\nTo counter this, in the JS code, it is important to make the relevant variables as functions in order to apply certain characteristics, such as clipping which works using base commands such as .median():\n\n// in this example, 'wollo' is the shapefile for the project, wollongong\n// data here collected from Sentinel-2\nvar waytwo = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n  .filterDate('2022-01-01', '2022-10-31')\n  .filterBounds(wollo)\n  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',20));\n  \n// initially we tried making the object work using \n// where maskS2clouds is a cloud cover function\nvar waytwo_masked = waytwo.map(maskS2clouds)\n// this does not work as the variable is not a function, but when adding the median() argument, this is no longer an issue\n// also allows for the removal of clouds as it takes the middle value of each pixel\nvar waytwo_masked = waytwo.map(maskS2clouds).median();\n\nvar waytwo_clip = waytwo_masked.clip(wollo)\n\nAlthough this took a while to figure out, trial and error has allowed to better understand how the different functions and notations work in Javascript which will be useful for following analysis.\n\n\n\n\nGuidotti, Riccardo, Anna Monreale, Salvatore Ruggieri, Franco Turini, Fosca Giannotti, and Dino Pedreschi. 2019. “A Survey of Methods for Explaining Black Box Models.” ACM Computing Surveys 51 (5): 1–42. https://doi.org/10.1145/3236009.\n\n\nLawrence, Rick L, and Andrea Wright. n.d. “Rule-Based Classification Systems Using Classification and Regression Tree (CART) Analysis.” PHOTOGRAMMETRIC ENGINEERING.\n\n\nLi, Jianfeng, Luyao Wang, Siqi Liu, Biao Peng, and Huping Ye. 2022. “An Automatic Cloud Detection Model for Sentinel-2 Imagery Based on Google Earth Engine.” Remote Sensing Letters 13 (2): 196–206. https://doi.org/10.1080/2150704X.2021.1988753.\n\n\nProbst, Philipp, Marvin N. Wright, and Anne-Laure Boulesteix. 2019. “Hyperparameters and Tuning Strategies for Random Forest.” WIREs Data Mining and Knowledge Discovery 9 (3): e1301. https://doi.org/10.1002/widm.1301.\n\n\nSilveira, Eduarda M. O., Sérgio Henrique G. Silva, Fausto W. Acerbi-Junior, Mônica C. Carvalho, Luis Marcelo T. Carvalho, Jose Roberto S. Scolforo, and Michael A. Wulder. 2019. “Object-Based Random Forest Modelling of Aboveground Forest Biomass Outperforms a Pixel-Based Approach in a Heterogeneous and Mountain Tropical Environment.” International Journal of Applied Earth Observation and Geoinformation 78 (June): 175–88. https://doi.org/10.1016/j.jag.2019.02.004.\n\n\nTang, Cheng, Damien Garreau, and Ulrike von Luxburg. 2018. “When Do Random Forests Fail?” In. Vol. 31. Curran Associates, Inc. https://proceedings.neurips.cc/paper/2018/hash/204da255aea2cd4a75ace6018fad6b4d-Abstract.html."
  },
  {
    "objectID": "correction_GEE_2.html",
    "href": "correction_GEE_2.html",
    "title": "Corrections in GEE - 2",
    "section": "",
    "text": "Defining the study area\nThis week we decide to focus on a politically difficult and unstable area: Kosovo. As it is not a recognised country by all authorities, it is difficult to work with. In our case, the regions were considered part of Serbia and we had to find a workaround in order to make clear boundaries. We circle in red the areas which are currently considered as Kosovan territory:\nThanks to community help we were able to get a union of multiple polygons through the following code with the inList argument allowing us to select multiple areas, which in our case delimitate Kosovo (code available here):\nBelow we include Kosovo with both the district boundaries and with the boundaries of the country as a whole:\nWe proceed to provide a true RBG image of the study area. We do so by selecting areas with less than 1% cloud cover. Yet, we realise that even within a large amount of time (between January and October 2022), there are certain tiles in the study area that do not have any observations with less than 1% cloud cover.\nWe decide to go with a study timeframe from January 2021 to October 2022, which provides us with a true cloudless image:"
  },
  {
    "objectID": "correction_GEE_2.html#novel-techniques---dynamic-world-example",
    "href": "correction_GEE_2.html#novel-techniques---dynamic-world-example",
    "title": "Corrections in GEE - 2",
    "section": "Novel Techniques - Dynamic World Example",
    "text": "Novel Techniques - Dynamic World Example\nIn this entry, we look at some slightly more advanced and novel techniques of classifications and topography understanding techniques, facilitated through GEE. A primary example of this is the Dynamic World project which aims to provide real-time data-sets of the physical material on the surfaces of the earth, compared to the traditional methods which had substantial lag times and were updated annually and inconsistent between image processing and data release ( Brown et al. (2022) ).\nThis project implementation has been successful and personally believe that the framework will be successful for better understanding of our environment. Dynamic world provides more detailed data than ever before which allows for better understanding of LULC and its evolution over time."
  },
  {
    "objectID": "correction_GEE_2.html#sub-pixel-classification",
    "href": "correction_GEE_2.html#sub-pixel-classification",
    "title": "Corrections in GEE - 2",
    "section": "Sub-Pixel Classification",
    "text": "Sub-Pixel Classification\nIn order to conduct sub-pixel classification, we first need to conduct spectral unmixing. Unmixing has been proven to allow for accurate extraction of surface material information ( Sun, Du, and Xiong (2017) ).\nWe add 5 different reference areas to account for the different terrains present in Kosovo:\n\nUrban\nWater\nForest\nBare Earth\n( Mountainous - we tried to include mountainous regions here as the southern and western Kosovo are areas with a lot of mountainous terrain. We thought that including this in our studied area may provide more input but this was not the case as too similar with ‘Bare Earth’ and we then decided to regroup the two categories. )\n\nAs previously, we included two runs of the sub-pixel analysis: one with the 5% cloud cover (but over a shorter period of time) and with 1% (over nearly two years).\nOur initial results are with the 5% cloud image are encouraging but present several issues\n\n\n5% cloud image as base of sub-pixel classification\n\n\nAlthough the urban areas are well defined, classified in red, we see that many of the cloudy areas in the south and west are also classified as containing urban areas when this is not actually the case\n\n\n\n\nUrban areas in red (left) and mis-classified cloudy areas also in red (right)\n\n\n\n\nWe run the analysis again using the 1% cloud cover image and the results are more encouraging\n\n\n1% cloud image sub-pixel classification\n\n\nGreen areas are now visible, which was not the case before hand. These areas represent ‘bare earth’ and ‘mountainous areas’.\nWe chose to regroup them as they were too similar and did not provide additional insight. The dark areas are areas which were not able to classified correctly as they did not contain sufficient terrain information to make accurate inference on the surface area (i.e. area was not able to be fully categorised into a single area)\nKosovo’s capital, the Urban area of Prisitna, is clearly defined in the classification task, with the agricultural areas defined to it’s right in green.\n\n\nPristina sub-classification\n\n\nWe also witness improvements in the mountainous regions, were previously the snow and clouds were confused as urban areas, and is no longer the case\n\n\nSouthern mountainous Kosovo correctly classified"
  },
  {
    "objectID": "correction_GEE_2.html#study-area-issues",
    "href": "correction_GEE_2.html#study-area-issues",
    "title": "Corrections in GEE - 2",
    "section": "Study Area issues",
    "text": "Study Area issues\nIt was interesting to note that in the GAUL data-set available on GEE, we cannot use ‘Pristina’, Kosovo’s Capital, as a study area. Although internationally recognized, this area does not appear in neither Level 1 or 2 nomenclature, which was an interesting discovery and illustrates possible limitations in the use of GAUL and GEE.\nWe also find some issues in the notation, as Kosovo is not recognised as a country, it makes working with the relevant shapefiles very difficult. The regions used to create the country shapefile were difficult to find and didn’t really have much continuity. The relevant ADM1_name codes used for this are 'Kosovsko-pomoravski', 'Kosovski', 'Kosovsko-mitrovatski', 'Pecki', 'Prizremski' but this is not logical notation, as it does not follow Kosovo’s current nomenclature. For example, the capital region is called ‘Kosovski’ in the GAUL dataset and Serbian Authorities, but ‘Pristina’ by the Kosovo government."
  },
  {
    "objectID": "correction_GEE_2.html#limitations-in-the-quality-of-the-model",
    "href": "correction_GEE_2.html#limitations-in-the-quality-of-the-model",
    "title": "Corrections in GEE - 2",
    "section": "Limitations in the quality of the model",
    "text": "Limitations in the quality of the model\nIn our case, by Selecting Kosovo, we took a country that has been under considerable political tension for the past decades. This entails population displacement and boundary issues, but it also influences the way in which people live in the country. For example, Kosovo has a low urbanization rate, at approx. 50%, (source: UN) compared to other European continent countries such as France and UK having higher rates at respectively 81% and 84% (source: Statista). This implies that in our sub-pixel analysis, and classification methods more generally, the urban areas are not as dense populated and do not represent perfectly an urban environment. Indeed, pixel in areas which we classy as urban may not be fully urban, meaning this could lead to certain miss-classifications.\nWe have an example of this in our analysis, near the “white Drin” river, where the sub-pixel spectral unfixing indicates signs of urban settlements near the river, which is not the case when looking at direct satellite imagery:\n\n\n\n\nWhite drin river, with spectral unfixing (left and urban classified areas in red) and real colour (right) view"
  },
  {
    "objectID": "correction_GEE_2.html#visualising-how-kosovo-was-classified",
    "href": "correction_GEE_2.html#visualising-how-kosovo-was-classified",
    "title": "Corrections in GEE - 2",
    "section": "Visualising how Kosovo was classified",
    "text": "Visualising how Kosovo was classified\nWe used two criteria of re-classification, comparing how the results change when the results are filtered. The first image provided has a pixel criteria of 0.5 and the second of 0.7. This means that when a pixel has more than 0.5 or 0.7 proportion of a certain land area, it will be classified as such.\n\n\n0.5 proportion criteria\n\n\nAbove, the different areas are quite well delimitated, as we can see delimited urban areas (pastel), bare earth/farmland (green), forest/mountain areas in beige and water (blue).\nOn the other hand, when using the 0.7 criteria, the image gets more confusing and the delimitations less clear\n\n\n0.7 proportion criteria\n\n\nFramework for accuracy assessments\nWe could use the reclassified areas and run Machine models to predict the number of correctly classified areas:\n\nmake ground truth data in the study area by classifying areas (either manually or through other forms)\nuse MESMA (Multiple end-member spectral mixture analysis) method to map land cover ( Dennison and Roberts (2003) )\nthese techniques allow to provide accuracy assessments of the study area"
  },
  {
    "objectID": "correction_GEE_2.html#clustering-methods",
    "href": "correction_GEE_2.html#clustering-methods",
    "title": "Corrections in GEE - 2",
    "section": "Clustering methods",
    "text": "Clustering methods\nFinally, we include the SNIC (Simple Non-Iterative Clustering) to identify different clusters in the surface area characteristics\n\n\nSNIC for Kosovo"
  },
  {
    "objectID": "correction_GEE_2.html#cloud-recognition-in-snowymountainous-areas",
    "href": "correction_GEE_2.html#cloud-recognition-in-snowymountainous-areas",
    "title": "Corrections in GEE - 2",
    "section": "Cloud recognition in snowy/mountainous areas",
    "text": "Cloud recognition in snowy/mountainous areas\nAlthough cloud identification is a major concern in remote sensing, and much research has focused on identifying clouds precisely, not having the algorithm confuse it with other elements such as snow ( Zhu and Woodcock (2014), Li et al. (2022) etc.) . In the snowy areas of Kosovo, we observed this to be the case as our cloud algorithm confused between these elements\n\n\nWestern Kosovo mountainous region confusing our cloud detection\n\n\nAs our work uses Landsat imagery, would look to use other algorithms such as F-mask and T-mask. F-mask uses single-date imagery and T-mask uses extra temporal information to fill in the missing information (Zhu and Woodcock (2014)). Specifically, this would be to continue our study of the area and monitor land cover change!\n\n\n\n\nBrown, Christopher F., Steven P. Brumby, Brookie Guzder-Williams, Tanya Birch, Samantha Brooks Hyde, Joseph Mazzariello, Wanda Czerwinski, et al. 2022. “Dynamic World, Near Real-Time Global 10 m Land Use Land Cover Mapping.” Scientific Data 9 (1): 251. https://doi.org/10.1038/s41597-022-01307-4.\n\n\nDennison, Philip E., and Dar A. Roberts. 2003. “Endmember Selection for Multiple Endmember Spectral Mixture Analysis Using Endmember Average RMSE.” Remote Sensing of Environment 87 (2): 123–35. https://doi.org/10.1016/S0034-4257(03)00135-4.\n\n\nLi, Jianfeng, Luyao Wang, Siqi Liu, Biao Peng, and Huping Ye. 2022. “An Automatic Cloud Detection Model for Sentinel-2 Imagery Based on Google Earth Engine.” Remote Sensing Letters 13 (2): 196–206. https://doi.org/10.1080/2150704X.2021.1988753.\n\n\nSun, Weiwei, Bo Du, and Shaolong Xiong. 2017. “Quantifying Sub-Pixel Surface Water Coverage in Urban Environments Using Low-Albedo Fraction from Landsat Imagery.” Remote Sensing 9 (5): 428. https://doi.org/10.3390/rs9050428.\n\n\nZhu, Zhe, and Curtis E. Woodcock. 2014. “Automated Cloud, Cloud Shadow, and Snow Detection in Multitemporal Landsat Data: An Algorithm Designed Specifically for Monitoring Land Cover Change.” Remote Sensing of Environment 152 (September): 217–34. https://doi.org/10.1016/j.rse.2014.06.012."
  },
  {
    "objectID": "correction_GEE_1.html#study-area-selection",
    "href": "correction_GEE_1.html#study-area-selection",
    "title": "Corrections in GEE - 1",
    "section": "Study area selection",
    "text": "Study area selection\nFor this entry, we focus on atmospheric correction in GEE, with specific on the Wollongong area, in New South Wales, Australia. We initially chose this region because the name is particularly interesting but also has the advantage of having interesting characteristics:\n\nis surrounded by the ocean on the east\nwilderness on the western side\nurban areas in Wollongong itself, providing ground contrast interesting to analyse."
  },
  {
    "objectID": "GEE_intro.html#study-area-selection",
    "href": "GEE_intro.html#study-area-selection",
    "title": "Introduction to Google Earth Engine",
    "section": "Study area selection",
    "text": "Study area selection\nInitially launched at a small scale in 2010 for Scientists and NGO’s, GEE has now been made available freely to the general public and provides a powerful tool for geo-spatial analysis! The ability of this service to analyse large scale data and provide results within seconds is not only unprecedented, but also allows for efficient research at high levels of granularity and methods that were computationally unavailable for the individual user. Instead of having to store this information locally, users like myself can use the Google Cloud Platform capabilities instead of local storage and machines.\nThis entry is an initial usage of the platform to familiarise myself with it, and provide initial impressions.\nThis entry will focus on analysis the characteristics of the ‘city of love’ and possibly one of the most exciting places in the world with exquisite food, Paris, France! 🇫🇷"
  },
  {
    "objectID": "GEE_intro.html#texture-analysis-in-gee",
    "href": "GEE_intro.html#texture-analysis-in-gee",
    "title": "Introduction to Google Earth Engine",
    "section": "Texture Analysis in GEE",
    "text": "Texture Analysis in GEE\nSimilar to one of our previous analyses, we choose to look at Gray Level Co-Occurrence Matrix (GLCM), a texture analysis which considers the spatial relationships of pixels in an image. Below, we include the contrast GCLM, which uses the contrast between neighbouring pixels as a measure of the texture.\n\n\nContrast GLCM\n\n\nAs a sanity check, we interpret the results from the image:\n\nLow Contrast at points in group 1 as these are the park areas of Paris (‘bois de Vincennes’ on the right and ‘hippodrome de Long-champs’ on the left). Due to low contrast, the GCLM does not indicate much texture change in the area, which is expected as they are all park/woodland areas\nHigh contrast at point 2, as this is the cultural and touristic center, notably including the Eiffel tower, small parks, Haussmannian 19th century buildings and recently built elements. So it is not a surprise that this area has high contrast values.\nFinally, area 3 follows part of the Seine. As this is the main water body in the city, we would expect high values of similarity which is is the case as there are many light pixels grouped together in that area!"
  },
  {
    "objectID": "GEE_intro.html#pca-in-gee",
    "href": "GEE_intro.html#pca-in-gee",
    "title": "Introduction to Google Earth Engine",
    "section": "PCA in GEE",
    "text": "PCA in GEE\nAlthough not as intuitive as the rasterPCA in RStoolbox, PCA analysis is possible in GEE. we find that the first 4 clusters account for more than 98% of the total variance of the studied area.\n\n\nValues of PCA clusters (in %)\n\n\nBelow we have an illustration of the four main groups visible. We see that a great deal of the variance is captured in the first frame. This is not a surprise as Paris is an Urban area and has quite strong similarities in terms of colours, and does not have a lot of variance with big contrasts between urban and green areas for example (parks are quite small compared to other cities, say London)."
  },
  {
    "objectID": "GEE_intro.html#band-maths",
    "href": "GEE_intro.html#band-maths",
    "title": "Introduction to Google Earth Engine",
    "section": "Band Maths",
    "text": "Band Maths\nNDVI\nThe Normalised Vegetation Index is the usual indicator of vegetation in an area. Here it makes sense that the values are higher in the park areas, closer to the outskirts of the city, than in the center which has a very high population density.\n\n\nThe Normalised Vegetation Index\n\n\nNDMI\nThe Normalised Moisture Index allows to collect information on the amount of moisture in the soil. The bands are calculated as follows in GEE:\n\nvar NDMI = clip.select('SR_B5').subtract(clip.select('SR_B6'))\n  .divide(clip.select('SR_B5').add(clip.select('SR_B6')))\n\nThe values go from -1 to 1, with the brown areas having the highest positive values. Again, most of the values are around 0 as the city has high building density. Nonetheless, the parks have high moisture value, with a strong brown colour.\n\n\nThe Normalised Moisture Index\n\n\nGCI\nThe Green Chlorophyll Index (GCI) is used to calculate the total amount of chlorophyll in plants. We thought using it in this project would be interesting to see the results but also it’s implementation in GEE. It was initially used in for MODIS ( Gitelson, Kaufman, and Merzlyak (1996) ) but as bands have similar characteristics between platforms, it can also be used on L-8.\n\nvar GCI = clip.select('SR_B5').divide(clip.select('SR_B5').add(1))\n\nBelow we have the illustration of the GCI. The values range between -1 and 1, with bright red representing a value of 1. In the case of Paris, we see that the values are mainly pinkish, representative of an urban environment, which is to be expected in Paris.\n\n\nThe Green Chlorophyll Index"
  },
  {
    "objectID": "temperature.html",
    "href": "temperature.html",
    "title": "Exploring temperature across urban areas",
    "section": "",
    "text": "Setting the scene\nDifferent global warming predictions exist, with experts trying to understand and estimate how human interaction with out environment can bring different possible scenarios. To illustrate these different possible outcomes, researchers have been using RCP’s to illustrate how our actions, or lack thereof, can influence global warming. The below image illustrates the evolution of the various different scenarios (Bowyer et al. (2014))\nThe different RCP values represent different actions taken at national and international level, with the following examples:\nFor this reason, properly analysing temperature, through Landsat or MODIS (or any other means) is important in understanding how heat evolves through time, seeing the effects on global warming on a global scale.\nIt also allows researchers to have insight on local level population insights and can support the well being of individuals. Indeed, indentifiying Urban Heat Islands, areas with dense concentrations of man-made buildings which accumulate heat, and implementing the correct policies to lower the temperature of these areas will benefit the living conditions of local populations. This is ever more so important as it allows cities to be in line with SDG\nAs the Bucharest area studied in this entry is only composed on a single spatial unit, we can only conduct statistics on a singular spatial unit. This is applicable both for Bucharest in the shapefile form and through the GAUL.\nIn further works, we would look to use areas which have spatial area separations which would allow us to make temperature comparisons between various areas or neighborhoods (depending on the granularity of the data available)\nWe would look to create a similar LST chart as in the previous section, but adding more lines for different recorded areas or sectors.\nIt would also be interesting to potential indexes for Heat, but also other measures such as moisture or dryness, to understand how certain urban areas are and how they influence the quality of life of local people.\nFinally, I highly values the skills, techniques and approaches used throughout the create of this Diary! I believe that, now accustomed to this panoply of methods to analyse remote sensing imagery, I have a much more developed understanding of current climate issues, but also how to implement and propose viable solutions. I look forward to continue developing these skills and had fun personalizing this work!"
  },
  {
    "objectID": "policy.html",
    "href": "policy.html",
    "title": "Policy discussion",
    "section": "",
    "text": "The problematic area\nFor the question of policy implementation, we focus on Romania’s Capital, Bucharest! Below we have it’s current delimiations\nBucharest suffers from many policy challenges due to incoherent decision making and high level of overlapping activity due to lack of communication. It is one of the only European cities without a coherent urban policy adopted by the state, as the decisions are taken on a local authority scale (Nica and Gavris (2009))\nOn of these, being the effects of droughts on the city. Researcher has been led to understand how drought has evolved in Romania since the 21st Century through the use of Remote Sensing ( Savin and Flueraru (2006) )\nMore recent work has focused on Bucharest Specific Land Cover usage over time ( Grivei and Datcu (2018) ) but has shown that the lack of in-depth research on these topics has made it hard to properly implement effective policies. This is why we select this OECD ‘Data Explorer’ as it would allow Romanian officials and researchers to benefit from the Drought index for example, and get a clear, reliable and unified view of the evolution that Romania has witnessed throughout the years.\nWe select the ‘Data Explorer’ source provided by the OECD. It is a data source that monitors exposure to climate-related hazards, consisting of 7 main categories, all constructed using remote sensing sources (Maes et al. (2022))\nOne of the most powerful tools of this database is it’s ability to provide near-real time results, which allows better understanding of various Characteristics, such as LULC, which is a factor with high variability which is not always captured.\nFurthermore, the data for all of these characteristics are available at a minimum since 1997 (for wildfires) and goes back up to 1950 (for drought info).\nWe add an example of the current interface that can be used by local researchers in order to tackle their current policy challenges, which could strongly benefit from this emerging datasource"
  },
  {
    "objectID": "temperature.html#landsat-8",
    "href": "temperature.html#landsat-8",
    "title": "Exploring temperature across urban areas",
    "section": "Landsat-8",
    "text": "Landsat-8\nL-8 has two thermal infrared band (c.f. with Band 10 and 11) which allow it to retrieve precise information on temperature trends, using single-channel or split-window algorithms to make these insights (Jiménez-Muñoz et al. (2014)). In our Bucharest analysis, we only use a single channel analysis to analyse our area, using band 10 from data between May and September 2022.\nWe run our first analysis on the Bucharest region, as delimited by the GAUL . With a temperature range between 20°C and 50°C (blue being coldest and red warmest), we see that our initial results are not too successful as much of the image is blue. This makes sense as Bucharest warmest ever temperature was of 42.2°C in 2000, therefore even with accumulation of heat, 50°C is a high margin.\n\n\nTemperature ranges Bucharest between 20°C and 50°C in summer 2022\n\n\nTo remedy this, we reduce the range to 20-45°C. With this change, the results are more insightful and we better visualise areas with high heat concentration. We also add the actual Bucharest outline (with local shapefile) which will be the area we focus on from this point forward:\n\n\nTemperature ranges Bucharest between 20 and 45°C\n\n\nThe output allows us to better see the variations in temperature but we also notice that some areas do not have values, either due to the lack of values, constant cloud cover over the area or simply the area being under 20°C:\n\n\nMissing Areas in Bucharest"
  },
  {
    "objectID": "temperature.html#modis-aqua-and-terra",
    "href": "temperature.html#modis-aqua-and-terra",
    "title": "Exploring temperature across urban areas",
    "section": "MODIS AQUA AND TERRA",
    "text": "MODIS AQUA AND TERRA\nNow moving on to the MODIS data, we use Aqua and Terra to visualise temperature in Bucharest. Our first results are less contrasted than for the L-8 data, and we also see that the area’s previously missing the L-8 are available for MODIS\n\n\nBucharest MODIS Temperature illustration\n\n\nFor better understanding of LST distribution around the city, the graph below provides precise quantitative information. We see peaks around August, with LST temperatures reaching 45°C. We also notice some data limitations as certain days do not seem to have information (i.e. early September or second quarter of July). This is likely due to some limiting factor, which could be simply cloud cover, as MODIS cannot observe the surface when cloud cover is present (NASA: NSDIC)\n\n\nGraphical Visualisation Temperature Bucharest Summer 2022\n\n\nTo provide better understanding of the above chart, we decide to use an interactive version of the chart, which allows for detailed information on the different temperature characteristics over time.\n\n\n\nLST Interactive Chart - Bucharest summer 2022"
  },
  {
    "objectID": "policy.html#limitations-of-the-data-source",
    "href": "policy.html#limitations-of-the-data-source",
    "title": "Policy discussion",
    "section": "Limitations of the Data Source",
    "text": "Limitations of the Data Source\nOne of the current limitations in the use of the ‘Data Explorer’ database is that it is still in the public beta release, as the initial launch of the programme was only in the second half of 2021. The beta release means that they are still testing new features in order to make sure all of their functionalities and data are correct.\nWe would also add, that current use of remote sensing for leakage detection is limited in terms of efficiency in highly dense and urban areas. We acknowledge this as it may affect the accuracy of the potential findings? Nonetheless, we are confident that, with the techniques in place, the quality of the equipment will increase and allow for more precise leakage detection in high density urban environments."
  },
  {
    "objectID": "policy.html#additional-information",
    "href": "policy.html#additional-information",
    "title": "Policy discussion",
    "section": "Additional information",
    "text": "Additional information\nFurther information can be found on the following Xaringan presentation, which was led by my classmates (Ella, Sophia, Yanbo and Winxi) and myself, where we develop on this topic. We focused particular on improving the population quality of life through the re-delimitation of Bucharest boundaries: available here!\n\n\n\n\nAgapiou, Athos, Dimitrios Alexakis, Kyriacos Themistocleous, and Diofantos Hadjimitsis. 2014. “Water Leakage Detection Using Remote Sensing, Field Spectroscopy and GIS in Semiarid Areas of Cyprus.” Urban Water Journal 13 (December): 1–11. https://doi.org/10.1080/1573062X.2014.975726.\n\n\nGrivei, A.-C., and M. Datcu. 2018. “IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium.” In, 1680–83. Valencia: IEEE. https://doi.org/10.1109/IGARSS.2018.8518615.\n\n\nMaes, Mikaël J. A., Abel Gonzales-Hishinuma, Ivan Haščič, Claire Hoffmann, Alexandre Banquet, Paolo Veneri, Alexandre Bizeul, Arnau Risquez Martin, and Roberta Quadrelli. 2022. “Monitoring Exposure to Climate-Related Hazards: Indicator Methodology and Key Results.” Paris. https://doi.org/10.1787/da074cb6-en.\n\n\nNica, Mariana, and Alexandru Gavris. 2009. “Public Policies In The Bucharest Metropolitan Area  Inertias And Challenges For Local Administation.” Proceedings of the Fifth \"Administration and Public Management\" International Conference: \"Public Institutions’ Capacity to Implement the Administrative Reform Process\", Bucharest, June 23-24, 2009, Proceedings of the Fifth \"Administration and Public Management\" International Conference: \"Public Institutions’ Capacity to Implement the Administrative Reform Process\", Bucharest, June 23-24, 2009,. https://ideas.repec.org//p/rom/confca/27.html.\n\n\nSavin, Elena, and Cristian Flueraru. 2006. “Use of Vegetation NDVI Time Series for Drought Monitoring in Romania.”"
  },
  {
    "objectID": "policy.html#successful-cities-that-have-overcome-similar-issues",
    "href": "policy.html#successful-cities-that-have-overcome-similar-issues",
    "title": "Policy discussion",
    "section": "Successful cities that have overcome similar issues",
    "text": "Successful cities that have overcome similar issues\nAlthough water correct and efficient water management has be a recurring issue in many cities, certain local governments have successfully managed to overcome these. For example, other European countries such as France are trying different methods to achieve this by re-using waste water.\nAlthough expensive, Romania does have the funds, especially with the support from the European union to implement this. We can also recommend using further techniques, in addition to our data source, to detect water leakage through remote sensing techniques using the Quick Bird Satellite and band measures such as NDVI (Agapiou et al. (2014)) , typically used for vegetation recognition, and used as a criteria for drought detection in our previous depiction of Romania."
  }
]