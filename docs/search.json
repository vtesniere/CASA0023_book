[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "Introduction and Presentation\nVlad’s Learning Diary and general thoughts on Remote Sensing Topics!\ntest does it update\n\n\n\n\nGitHub maximum file upload of 50mb. Source: reddit r/ProgrammerHumor"
  },
  {
    "objectID": "index.html#introduction-and-presentation",
    "href": "index.html#introduction-and-presentation",
    "title": "CASA0023 Learning Diary",
    "section": "Introduction and Presentation",
    "text": "Introduction and Presentation\nVlad’s Learning Diary and general thoughts on Remote Sensing Topics!\ntest does it update\n\n\n\n\nGitHub maximum file upload of 50mb. Source: reddit r/ProgrammerHumor"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "\n1  Introduction\n",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Policy",
    "section": "",
    "text": "define what a policy actually is\ndefine why it is useful and how we can develop it\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "intro.html#basic-raster-image-processing-and-statistics",
    "href": "intro.html#basic-raster-image-processing-and-statistics",
    "title": "Introducing Remote Sensing - A Bucharest Analysis",
    "section": "Basic Raster image processing and statistics",
    "text": "Basic Raster image processing and statistics\nOur images presented below, were collected on the 27th and 17th of October 2022 for Sentinel and Landsat respectively. They are both true color images (TCI) with the Red, Green and Blue bands present.\n\n\n\n\n\n\n\nSentinel-2 (left) and Landsat-8 (Right) TCI over Bucharest (October 2022)\n\n\n\n We have a more recent view available of the Landsat imagery (24th of October) but prefer not to use it as more impurities are present. We will tackle this in future Diary entries with the introduction of atmospheric correction.\n\n\n\n\nRBG image from 24/10, not used in examples but presented for visibility\n\n\n\n\n\nWe continue to explore our data by looking at the different colour composites in the sentinel images:\n\n\n\n\nAtmospheric Penetration (left), False Colour Infrared (Middle), B1 band (right)\n\n\n\n\nIs it interesting to try and understand what the colours mean in these images. For example, the middle image, False Colour Composite (using bands B8, B4 and B3) aims to show the physiography of the terrain showing soil and land-resources which has been common practice since the 20th century (Reddy et al. (1990)). As our study area is primarily urban (Bucharest located in the bottom-left corner), we see that many of the red colours bands are absorbed, signifying a lack of vegetation in the Capital, compared to rural areas on the right side of the image.\nThe same is true for the left image, the atmospheric penetration, where we recognise distinct urban areas due to the purple/gray cyan colours in the bottom-left corner. Finally, the right side image provides a raw overview of the sentinel imagery, and specifically the B1 band. the B1 band is used for the Coastal and Aerosol information, with a detailed description of Bands available here!"
  },
  {
    "objectID": "intro.html#understanding-the-differences-between-sentinel-2-and-landsat",
    "href": "intro.html#understanding-the-differences-between-sentinel-2-and-landsat",
    "title": "2  Introducing Remote Sensing - A Bucharest Analysis",
    "section": "2.2 Understanding the differences between Sentinel 2 and Landsat",
    "text": "2.2 Understanding the differences between Sentinel 2 and Landsat\nNow that we have images from both sources, we proceed to resample the images to the same resolution. Below we have a comparison of the bands between Sentinel-2 and Landsat-8.\n\n\n\nComparison of Sentinel and Landsat Bands, taken from López-Puigdollers, Mateo-García, and Gómez-Chova (2021)\n\n\nYet this is not enough as in order to make cross-platform comparisons successful! Below we have a detailed overview comparing band resolution between Sentinel and Landsat, with respective links to sources of Table 1 (left) and Table 2 (right)!\n\n\n\n\n\nSentinel-2 (left) and Landsat-8 (right) band comparisons\n\n\n\nWe see that the two platforms share certain similar characteristics, but differences are notable. For example, even if the Blue, Green and Red Channels are present on both, their wavelengths do not overlap perfectly. Furthermore, both platforms do not have all the same bands, with 1,2,3,4 overlapping similarly and B11 and B12 on S-2 working with B6 and B7 on L-8. In our application today, we will only be using Bands 2 to 4 on both, B6 and 7 on Landsat and B8 and 12 on Sentinel.\nMost importantly, these two platforms do not share the same resolutions, with L-8 principally outputting at 30m compared to S-2 between 10, 20 or 60m.\nTo overcome this, we upscale the Sentinel Imagery to Fit the 30m resolution displayed by Landsat. As we decide to focus on Bucharest specifically, we also subset the image to only the city outline using shapefiles provided by GADM. The clipped results are as follows:\n\n\n\n\n\nSentinel-2 (left) and Landsat-8 (right) clipped RBG images of Bucharest (at same resolution)"
  },
  {
    "objectID": "intro.html#my-thoughts-and-interpretation-of-the-tool",
    "href": "intro.html#my-thoughts-and-interpretation-of-the-tool",
    "title": "Introducing Remote Sensing - A Bucharest Analysis",
    "section": "My thoughts and interpretation of the tool",
    "text": "My thoughts and interpretation of the tool\nAs this was my first confrontation with Satellite imagery analysis, I was highly interested in discovering the techniques. I was happy to be able to choose my own study area and focus on my hometown!\nIn terms of analysis, it was enthused to learn about the amount of satellite data freely available on Copernicus Open Access Hub and Earth Explorer! I took the liberty to play around with these tools and fully grasp how they work and how i could use them. The image extraction for L-8 and S-2 was quite straightforward and allowed further exploration than just the Bucharest imagery used here.\nThe following steps which included using SNAP and QGIS to look, analyse, subset and re-sample the L-8 and S-2 images. This was already slightly more complicated as I had to get accustomed to the SNAP application, it’s layout, utilities and characteristics.\nI for example played around with the RBG histogram when portraying my RBG images, notably putting a 100% display to understand how the image statistics work\n\n\n\n\n100% pixel display when getting exploring SNAP\n\n\n\n\nI bumped into several issues early on, where I for example could not do the tasseled cap transformation completely. I understood and successfully presented the scatter plots between bands (B4 and B8). Unfortunately, I was not able to compute the tasseled cap transformation with the specific band equations. This is something I hope to develop on and be able to include in the coming weeks.\n\n\n\n\nBucharest Spectral Feature - tasseled cap scatterplot\n\n\n\n\nFinally, using computational methods to compare the results between L-8 and S-2 bands allowed me to gain a better understand of general functioning of spectral bands. I was happy to have made mistakes in my initial analysis with it’s summary presented below:\n\n\nInitial results of Computation Analysis, with non-equivalent bands between S-2 and L-8\n\n\nIn my first results, I made the mistake of comparing the wrong bands, comparing B8 in S-2 and B6 in Landsat which do not measure similar aspects. For this reason, the Band 4 in the above table fo not make sense, in the Sentinel Observations the grass values being much too high! Furthermore, from a visualisation perspective, the colors are not coordinated with the usually considered colours (i.e. grass as green) which make the presentation of the results more confusing.\nAll in all, this first approach was beneficial and very much enjoyed! Understanding how both S-2 and L-8 bands function was not always easy, but with trial and error the final results make sense! We were able to show comparisons between L-8 and S-2 for locally defined POI’s and provided a good initiation in understanding similarities and differences between platforms.\n\n\n\n\nLefebvre, Antoine, Christophe Sannier, and Thomas Corpetti. 2016. “Monitoring Urban Areas with Sentinel-2A Data: Application to the Update of the Copernicus High Resolution Layer Imperviousness Degree.” Remote Sensing 8 (7): 606. https://doi.org/10.3390/rs8070606.\n\n\nLópez-Puigdollers, Dan, Gonzalo Mateo-García, and Luis Gómez-Chova. 2021. “Benchmarking Deep Learning Models for Cloud Detection in Landsat-8 and Sentinel-2 Images.” Remote Sensing 13 (5): 992. https://doi.org/10.3390/rs13050992.\n\n\nNistor, Constantin, Marina Vîrghileanu, Irina Cârlan, Bogdan-Andrei Mihai, Liviu Toma, and Bogdan Olariu. 2021. “Remote Sensing-Based Analysis of Urban Landscape Change in the City of Bucharest, Romania.” Remote Sensing 13 (12): 2323. https://doi.org/10.3390/rs13122323.\n\n\nReddy, R. S., S. Thayalan, C. R. Shiva Prasad, P. S. A. Reddy, and J. L. Sehgal. 1990. “Utility of Satellite Data for Land Evaluation in Land Use Planning for a Part of Northern Karnataka.” Journal of the Indian Society of Remote Sensing 18 (4): 34–44. https://doi.org/10.1007/BF02997071."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Balázs, Boglárka, Tibor Bíró, Gareth Dyke, Sudhir Kumar Singh, and\nSzilárd Szabó. 2018. “Extracting Water-Related Features Using\nReflectance Data and Principal Component Analysis of Landsat\nImages.” Hydrological Sciences Journal 63 (2): 269–84.\nhttps://doi.org/10.1080/02626667.2018.1425802.\n\n\nChavez, Pat S. 1996. “Image-Based Atmospheric Corrections -\nRevisited and Improved.”\n\n\nGhimire, Prakash, Deng Lei, and Nie Juan. 2020. “Effect of Image\nFusion on Vegetation Index QualityA Comparative Study from\nGaofen-1, Gaofen-2, Gaofen-4, Landsat-8 OLI and MODIS Imagery.”\nRemote Sensing 12 (10): 1550. https://doi.org/10.3390/rs12101550.\n\n\nHall-Beyer, Mryka. 2017. “GLCM Texture: A Tutorial v. 3.0 March\n2017,” March. https://doi.org/10.11575/PRISM/33280.\n\n\nHuete, A. R. 1988. “A Soil-Adjusted Vegetation Index\n(SAVI).” Remote Sensing of Environment 25 (3): 295–309.\nhttps://doi.org/10.1016/0034-4257(88)90106-X.\n\n\nKaufman, Y. J., and D. Tanre. 1992. “Atmospherically Resistant\nVegetation Index (ARVI) for EOS-MODIS.” IEEE Transactions on\nGeoscience and Remote Sensing 30 (2): 261–70. https://doi.org/10.1109/36.134076.\n\n\nKupidura, Przemysław. 2019. “The Comparison of Different Methods\nof Texture Analysis for Their Efficacy for Land Use Classification in\nSatellite Imagery.” Remote Sensing 11 (10): 1233. https://doi.org/10.3390/rs11101233.\n\n\nLefebvre, Antoine, Christophe Sannier, and Thomas Corpetti. 2016.\n“Monitoring Urban Areas with Sentinel-2A Data: Application to the\nUpdate of the Copernicus High Resolution Layer Imperviousness\nDegree.” Remote Sensing 8 (7): 606. https://doi.org/10.3390/rs8070606.\n\n\nLópez-Puigdollers, Dan, Gonzalo Mateo-García, and Luis Gómez-Chova.\n2021. “Benchmarking Deep Learning Models for Cloud Detection in\nLandsat-8 and Sentinel-2 Images.” Remote Sensing 13 (5):\n992. https://doi.org/10.3390/rs13050992.\n\n\nMunyati, Christopher. 2004. “Use of Principal Component Analysis\n(PCA) of Remote Sensing Images in Wetland Change Detection on the Kafue\nFlats, Zambia.” Geocarto International 19 (3): 11–22. https://doi.org/10.1080/10106040408542313.\n\n\n“NDVI, the Foundation for Remote Sensing Phenology | u.s.\nGeological Survey.” n.d. https://www.usgs.gov/special-topics/remote-sensing-phenology/science/ndvi-foundation-remote-sensing-phenology.\n\n\nNistor, Constantin, Marina Vîrghileanu, Irina Cârlan, Bogdan-Andrei\nMihai, Liviu Toma, and Bogdan Olariu. 2021. “Remote Sensing-Based\nAnalysis of Urban Landscape Change in the City of Bucharest,\nRomania.” Remote Sensing 13 (12): 2323. https://doi.org/10.3390/rs13122323.\n\n\n“Normalized Difference Moisture Index | u.s. Geological\nSurvey.” n.d. https://www.usgs.gov/landsat-missions/normalized-difference-moisture-index.\n\n\nQi, J., A. Chehbouni, A. R. Huete, Y. H. Kerr, and S. Sorooshian. 1994.\n“A Modified Soil Adjusted Vegetation Index.” Remote\nSensing of Environment 48 (2): 119–26. https://doi.org/10.1016/0034-4257(94)90134-1.\n\n\nReddy, R. S., S. Thayalan, C. R. Shiva Prasad, P. S. A. Reddy, and J. L.\nSehgal. 1990. “Utility of Satellite Data for Land Evaluation in\nLand Use Planning for a Part of Northern Karnataka.” Journal\nof the Indian Society of Remote Sensing 18 (4): 34–44. https://doi.org/10.1007/BF02997071.\n\n\nSchulte to Bühne, Henrike, and Nathalie Pettorelli. 2018. “Better\nTogether: Integrating and Fusing Multispectral and Radar Satellite\nImagery to Inform Biodiversity Monitoring, Ecological Research and\nConservation Science.” Methods in Ecology and Evolution\n9 (4): 849–65. https://doi.org/10.1111/2041-210X.12942.\n\n\nSegal-Rozenhaimer, Michal, Alan Li, Kamalika Das, and Ved Chirayath.\n2020. “Cloud Detection Algorithm for Multi-Modal Satellite Imagery\nUsing Convolutional Neural-Networks (CNN).” Remote Sensing of\nEnvironment 237 (February): 111446. https://doi.org/10.1016/j.rse.2019.111446.\n\n\nYuan, Karen, Patrick O’Neil, and Diego Torrejon. 2020. “8 -\nLandsat’s Past Paves the Way for Data Democratization in Earth\nScience.” In, edited by Feras A. Batarseh and Ruixin Yang,\n147–61. Academic Press. https://doi.org/10.1016/B978-0-12-818366-3.00008-3."
  },
  {
    "objectID": "abbreviations.html",
    "href": "abbreviations.html",
    "title": "Common Remote Sensing Abbreviations!",
    "section": "",
    "text": "As remote sensing can get quite complex in terms of nomenclature, this abbreviation index can come in handy when potential concept explanations are not clear!\n\nRBG : Red, Blue Green\nTOA : Top of Atmosphere\nL-8 : Landsat-8 Satellite\nS-2 : Sentinel-2\nGEE : Google Earth Engine\nSNAP : Sentinel Application Platform is provided by the ESA/ESRIN and allows the Earth Observation Community with a free tool to process and analyse satellite imagery. It has the advantage of providing InSAR Processing capabilities, which is not yet the case with GEE\nPOI : Points of Interest - these are points that are representative of certain land-cover types and allows for comparison between platforms. This was for example used in the Bucharest Analysis where we used reference area for water, green area and industrial area to compare L-8 and S-2 imagery.\nESA : European Space Agency\nESRIN : ESA center for earth Observation created in 1966 and currently based in Frascati, Italy\nSWIR : Short-wave infrared, part of the electromagnetic spectrum and allows for identification of objects invisible to the human eye and traditional multi-spectral bands. It can allow for the identification of certain terrain characteristics (i.e. certain bands in SWIR is more highly absorbed by water bodies). Ranges from 1.4 to 3 µm (micrometers)\nNIR : Near infra-red\nDOS : Dark Object Subtraction - Method to correct raw satellite imagery by considering the true value of the darkest pixel in the image as 0. If this is not the value of said pixel, this is attributed to variations caused by the atmosphere\nNDVI : Normalised Difference Vegetation Index - Index determining the density of live vegetation in a particular area. The formula for this is: \\[NDVI= \\frac{NIR-Red}{NIR+Red}= \\frac{Landsat B5 - Landsat B4} {Landsat B5 + Landsat B4}\\] The values range between -1 and 1: 0.1 and below considered low values, between 0.2 and 0.5 moderate values (i.e. shrubs and grass-land) and high values between 0.6 and 0.9 (typically dense vegetation, forests, fertile crops) “NDVI, the Foundation for Remote Sensing Phenology | u.s. Geological Survey” (n.d.)\nNDMI : Normalised Difference Moisture Index - Similar methodology and interpretation to NDVI but here determines vegetation water content “Normalized Difference Moisture Index | u.s. Geological Survey” (n.d.) . For Landsat 8-9, the formula is as follows: \\[NDMI= \\frac{NIR-SWIR}{NIR+SWIR}= \\frac{Landsat B5 - Landsat B6} {Landsat B5 + Landsat B6}\\]\nIFOV : Instantaneous Field of View\nSAR : Synthetic Aperture Radar\nNadir : celestial sphere directly below an observer\nAzimuth : the direction of a celestial object from the observer, calculated through distance from horizon from a cardinal point (usually north or south)\nPCA : Principal Component Analysis - is a method of unsupervised learning which aims to reduce the number of dimensions whilst still keeping most of the information. In remote sensing this is particularly useful as it can help understand and visualise where changes in terrain characteristics have taken place ( Munyati (2004) )\nGLCM : gray-level co-occurrence matrix which is a method that examines textures whilst considering the spatial relationship of the pixels. Several different methods can be applied which prioritize different pixel characteristics (i.e. homogeneity, contrasts etc.)\n\n\n\n\n\nMunyati, Christopher. 2004. “Use of Principal Component Analysis (PCA) of Remote Sensing Images in Wetland Change Detection on the Kafue Flats, Zambia.” Geocarto International 19 (3): 11–22. https://doi.org/10.1080/10106040408542313.\n\n\n“NDVI, the Foundation for Remote Sensing Phenology | u.s. Geological Survey.” n.d. https://www.usgs.gov/special-topics/remote-sensing-phenology/science/ndvi-foundation-remote-sensing-phenology.\n\n\n“Normalized Difference Moisture Index | u.s. Geological Survey.” n.d. https://www.usgs.gov/landsat-missions/normalized-difference-moisture-index."
  },
  {
    "objectID": "intro.html#understanding-the-differences-between-s-2-and-l-8",
    "href": "intro.html#understanding-the-differences-between-s-2-and-l-8",
    "title": "Introducing Remote Sensing - A Bucharest Analysis",
    "section": "Understanding the differences between S-2 and L-8",
    "text": "Understanding the differences between S-2 and L-8\nNow that we have images from both sources, we proceed to re-sample the images to the same resolution. Below we have a comparison of the bands between Sentinel-2 and Landsat-8.\n\n\nComparison of Sentinel and Landsat Bands, taken from López-Puigdollers, Mateo-García, and Gómez-Chova (2021)\n\n\nYet this is not enough as in order to make cross-platform comparisons successful! Below we have a detailed overview comparing band resolution between Sentinel and Landsat, with respective links to sources of Table 1 (left) and Table 2 (right)!\n\n\n\nSentinel-2 (left) and Landsat-8 (right) band comparisons\n\n\n\nWe see that the two platforms share certain similar characteristics, but differences are notable. For example, even if the Blue, Green and Red Channels are present on both, their wavelengths do not overlap perfectly. Furthermore, both platforms do not have all the same bands, with 1,2,3,4 overlapping similarly and B11 and B12 on S-2 working with B6 and B7 on L-8. In our application today, we will only be using Bands 2 to 4 on both, B6 and 7 on Landsat and B8 and 12 on Sentinel.\nMost importantly, these two platforms do not share the same resolutions, with L-8 principally outputting at 30m compared to S-2 between 10, 20 or 60m.\nTo overcome this, we upscale the Sentinel Imagery to Fit the 30m resolution displayed by Landsat. As we decide to focus on Bucharest specifically, we also subset the image to only the city outline using shapefiles provided by GADM. The clipped results are as follows:\n\n\n\n\nSentinel-2 (left) and Landsat-8 (right) clipped RBG images of Bucharest (at same resolution)\n\n\n\nSelecting our Points of Interest\nNow that we have our clipped view of Bucharest, we select 3 POI’s which are Green Area (Pădurea Băneasa), Water (the Morii lake) and Industrial Area (Industriilor Sector). With these representations that serve as a landmark, we will be able to make comparisons between L-8 and S-2 data.\n\n\n1. Green Area, 2. Water, 3. Industrial Area\n\n\nComputational Analysis of L-8 and S-2 Images\nNow that we have our reference POI’s in place, we were able to input this data in RStudio and analyse the spectral signatures. We acknowledged beforehand that both of these sensors had a dozen bands each, but in this case, we only kept 4 overlapping bands, which are Blue, Green and Red (B2, B3 and B4) and SWIR (B12 on S-2 and B7 on L-8).\nOur results are presented below, with bands 1, 2, 3 and 4 representing Blue, Green, Red and SWIR:\n\n\nComparison of Band Values, A and B showing S-2 and C and D are L-8 results\n\n\nWith the above image, we get an overview of the different bands that coincide between L-8 and S-2 when analysing our POI’s. Our green line, which represents the green areas in Bucharest Urban area, shows similar trends between L-8 and S-2. The same if true for industrial and water areas, showing that the bands between L-8 and S-2 react similarly. Furthermore, the density plots are also encouraging as they have the same shapes and similar reactions to the various POI’s. Nonetheless, even if the bands follow similar movement, we acknowledge that the values are not the same. For example, the average band water for the grassy area is around 1500 for S-2 whereas this value is at 2500 for the same area in L-8.\nIt is interesting to note that the Water POI has the least variation in band values, with the highest pixel density in both platforms. This is followed by the grassy area. Finally, the industrial area has greater spread of band values.\nIt is not surprising that the industrial area had the most variation as, not only was our initial POI Shape 3 had a little overlap over water areas, but also had the least uniformity in content (aka not purely industrial areas but included houses, roads etc.). Urban areas are known to have more variation in band values ( Lefebvre, Sannier, and Corpetti (2016) ). This also explains why the confidence intervals in the industrial area are much broader than for the other two categories."
  },
  {
    "objectID": "corrections.html",
    "href": "corrections.html",
    "title": "Atmospheric Corrections",
    "section": "",
    "text": "Collecting and merging raster images\nFor this topic, we decide to analyse the whole of Tasmania. Tasmania is has a landmass of over \\(68,000 km^2\\). A cloud-clear Landsat Image provides overview on approximately \\(34,000km^2\\) which means that several captures are necessary. Below is an example of a single image over Tasmania, not enough to be representative of the island as a whole. We need to merge several to create a mosaic. Below we use these 7 panes and put them in a mosaic to create a full RBG view of the Island\nWe took our images from the USGS and used 7 images in total to cover the whole Island. Of these 7 images, 5 came from Landsat 8 and 2 from Landsat 9. Six of the frames were taken between 24th and 28th of January 2022 and one of them was on the 12th of February 2022. We deemed this temporal difference between images not to be significant but we will be analysing the implications further down.\nThe bands presented here are at 30m resolution. We omit bands 8 (15m), 10 and 11 (100m) as they have different resolutions (refresher table available here). As the information that spectral bands can provide is high, we can use this to get additional insight on our area of study!\nAs Tasmania is known as an important microcosm, home to many endemic species both of animals and vegetation, we look at at vegetation measures. Using NIR and Red bands in L-8/9 we can understand vegetation intensity across the island. The below panel illustrates which areas meet different thresholds of NDVI:\nWe see that a great proportion of Tasmanian Landmass has positive levels of NDVI, which would indicate that there are little to no areas of barren rocky or sandy surfaces (US Geological Society). This is not surprising as over 50% of Tasmania’s land area has some form of reservation classification.\nTo continue understanding the Tasmania’s composition, we also focus on the moisture index. NDMI is used to determine vegetation water content and is measured similarly to NDVI. Below we have a similar breakdown of the different areas across various thresholds:\nAs expected, the land areas have overwhelmingly positive values! In addition we have to keep in mind the temporal aspect as these observations were taken in the southern Hemisphere summer which means these values are likely to be higher during the traditionally wetter seasons of June, July and August (source)\nThe principal issue encountered for this analysis came in using the 'Rtools' and 'RStoolbox' packages. Indeed, different dependencies and technical differences (Mac vs Windows and R version 4.2.2 and 4.2.1) made using them difficult, specifically the 'rasterPCA' function.\nThis allowed me to gain better understanding of library development as I had to use the source code for the specific PCA function (master code here) and then download the appropriate objects as internal functions (here). We thank Benjamin Leutner for developing the packages and making the source code available. With this difficulty, I was able to dive deeper into the working of computing for corrections in Remote Sensing.\nAs for corrections in general, I was unfamiliar with this topic before but found it rewarding and insightful. The amount of information possible to extract from raw spectral data is impressive and is something I want to explore further. Although we only used NDVI and NDMI in this analysis, we have more options which could include:\nAlso interesting to see how the democratisation of data availability in remote sensing paired with technological has allowed for facilitated research on earth’s surface (Schulte to Bühne and Pettorelli (2018) ) . For example, the Landsat programme which has been running since 1972 gives the ability to see how methods change over time ( Yuan, O’Neil, and Torrejon (2020) ). These technological advances are important in correction with examples such as machine learning using Convolutional Neural Networks (CNN) to automatically identify the presence of clouds in images ( Segal-Rozenhaimer et al. (2020) ).\nFinally, the same is true for texture analysis. In our Tasmanian Analysis, we only focused on grey level co-occurrence matrix to use in the process of land use/cover classification. We could aim to use other methods in future analyses such as Laplace filters and granulometric analysis ( Kupidura (2019) )"
  },
  {
    "objectID": "2_sensor_presentation.html",
    "href": "2_sensor_presentation.html",
    "title": "Presenting a Sensor: Sentinel 6A and the Poseidon-4 Radar Altimeter",
    "section": "",
    "text": "For this part of the project, another platform was used: Xaringan\nThis new platform allows for the creation of Slides through R! This is a first attempt at using this type of slides and has the ability of being embedded directly into our Quarto blog!! (At the cost of some interactivity and lost formats..)\n\n\n\n\n\n\n\n\nThis is a really efficient way of sharing the slides, even if we can recognise certain issues the readability of the slides. Indeed, we see that when we scroll down, the slides are not always easy to control and tend to go by too quickly!\nFor full screen presentation of these slides, they are available here! (link opens in new tab)\n\n\n\n \n\n      \n         Introducing Remote Sensing - A Bucharest Analysis\n                \n  \n  \n      \n        Atmospheric Corrections"
  },
  {
    "objectID": "corrections.html#texture-and-filtering",
    "href": "corrections.html#texture-and-filtering",
    "title": "Atmospheric Corrections",
    "section": "Texture and Filtering",
    "text": "Texture and Filtering"
  },
  {
    "objectID": "corrections.html#finding-clusters-and-common-characteristics",
    "href": "corrections.html#finding-clusters-and-common-characteristics",
    "title": "Atmospheric Corrections",
    "section": "Finding Clusters and common characteristics",
    "text": "Finding Clusters and common characteristics\nWe now proceed to look at Principal Component Analysis (PCA) which aims to reduce the dimensionality in texture bands and provide easier understanding of the environmental information, whilst preserving most of the information. So it has the benefit of providing clear overviews of changes, such as variations of terrain characteristics.\n\n\n\n\n\n   \n    Component 1 \n    Component 2 \n    Component 3 \n    Component 4 \n    Component 5 \n    Component 6 \n    Component 7 \n    Component 8 \n    Component 9 \n  \n\n\n Standard deviation \n    2.5547583 \n    1.1690118 \n    0.7963765 \n    0.5411714 \n    0.3271707 \n    0.2268870 \n    0.0996739 \n    0.0921788 \n    0.0508813 \n  \n\n Proportion of Variance \n    0.7251989 \n    0.1518432 \n    0.0704684 \n    0.0325407 \n    0.0118934 \n    0.0057197 \n    0.0011039 \n    0.0009441 \n    0.0002877 \n  \n\n Cumulative Proportion \n    0.7251989 \n    0.8770421 \n    0.9475105 \n    0.9800512 \n    0.9919446 \n    0.9976644 \n    0.9987682 \n    0.9997123 \n    1.0000000 \n  \n\n\n\n\nAs the above table provides information regarding numerical information, we can get a better understanding of how spectral data of Tasmanian L-8 imagery (during the summer season or 2022) varies. We identify that over 98% of the spectral variance is contained within the first 4 clusters. Using PCA in remote sensing provides several advantages as it allows to visualise the changes that occurred in a certain area ( Munyati (2004) ) and reduce the dimensionality of the spectral data ( Balázs et al. (2018) ). This may be difficult to interpret numerically, therefore we include visualisation of the top 4 components in the image below:\n\n\nIllustration of top 4 PCA bands for our study area"
  },
  {
    "objectID": "corrections.html#differences-between-panes",
    "href": "corrections.html#differences-between-panes",
    "title": "Atmospheric Corrections",
    "section": "Differences between panes",
    "text": "Differences between panes\nWe note that in our initial image, with the 7 panes, there are temporal differences between when each of them were captured, especially one of them taken more than two weeks later (top left). Not only is it taken later, but we also see the strong presence of clouds (i.e. Band 9 top left and visually with the white areas). Below we have the same mosaic but instead keep only 6 panes which were taken within 4 days of each other:\n\n\nMosaic without temporal outlier\n\n\nWe add this difference for visibility but also to show that time and cloud cover are very important aspect and can influence image results. In our case, even if the differences are visible in the later image, we will continue will all 7 in our analysis below to get a full idea of the island, even if the results may not be perfectly precise."
  },
  {
    "objectID": "corrections.html#texture",
    "href": "corrections.html#texture",
    "title": "Atmospheric Corrections",
    "section": "Texture",
    "text": "Texture\nWe use filtering on our images to reduce the computational weight of the image and make it easier for processing in the below texture analysis.\nWe use the Gray level co-occurrence matrix (GLCM) to understand how different regions are characterised. It considers spatial relationships between pixels simultaneously to understand how the textures compare between areas of the mosaic.\n\n\nNIR Band Texture\n\n\nWith this panel, we are able to start visualising different terrain characteristics. The different categories indicate what characteristics are focused on between analysed neighbouring pixels.\nFor example, the ‘contrast’ pane emphasises areas with high contrast between neighbouring pixels, which in this case has value in the upper center part of the island. Which makes sense as Hobart, the capital of Tasmania, is in that area and there would be contrast between urban and forests for example. As for another value such as ‘homogeneity’, the values are higher towards the center of the island which is the least urbanised, thus having most similar surroundings, mainly covered by forests ( Hall-Beyer (2017) and additional breakdowns of the characteristics starting page 29)."
  },
  {
    "objectID": "GEE_intro.html#exploring-the-examples-in-the-script-editor",
    "href": "GEE_intro.html#exploring-the-examples-in-the-script-editor",
    "title": "Introduction to Google Earth Engine",
    "section": "Exploring the Examples in the script editor",
    "text": "Exploring the Examples in the script editor\nThe interface is easy to use and provides a panoply of different scripts to get accustomed to the different uses of the platform.\nLearning to use Javascript - JavaScript (JS) is a scripting/programming language which allows for the implementation of dynamic behaviour and updating control multimedia. In our case, we use JavaScript to use the GEE API and access their satellite imagery data and analysis capabilities (GEE platform)."
  },
  {
    "objectID": "GEE_intro.html#exploring-paris-with-gee",
    "href": "GEE_intro.html#exploring-paris-with-gee",
    "title": "Introduction to Google Earth Engine",
    "section": "Exploring Paris with GEE",
    "text": "Exploring Paris with GEE\nWe start by playing around with the Earth Engine to get a better idea and understanding of what tools are available to us. Our aim is to analyse Paris and it’s characteristics so we start off by taking the appropriate shapefile ('GID_2 == \"FRA.8.3_1\"') from GADM.\nThe images we use are from L-8 and Level 2, Collection 2 tier 1 images (additional info on L-8 tiers here). They were collected between June 2020 and October 2022.\nAfter being able to clip the city as a whole, we compare the images:\n\nLeft image shows Clipped Paris untouched (aka without any transformations). We see that the image is mostly black as no correction has been made\nRight Image shows Paris with the appropriate adjustment for surface reflectance through scaling factors\n\n\n\n\n\nInitial clip of Paris, including not transformed (left) and adjusted for surface reflectance (right)"
  },
  {
    "objectID": "GEE_intro.html#taking-the-analysis-further",
    "href": "GEE_intro.html#taking-the-analysis-further",
    "title": "Introduction to Google Earth Engine",
    "section": "Taking the Analysis further",
    "text": "Taking the Analysis further\nTexture Analysis in GEE\nSimilar to one of our previous analyses, we choose to look at Gray Level Co-Occurrence Matrix (GLCM), a texture analysis which considers the spatial relationships of pixels in an image. Below, we include the contrast GCLM, which uses the contrast between neighbouring pixels as a measure of the texture.\n\n\nContrast GLCM\n\n\nAs a sanity check, we interpret the results from the image:\n\nLow Contrast at points in group 1 as these are the park areas of Paris (‘bois de Vincennes’ on the right and ‘hippodrome de Long-champs’ on the left). Due to low contrast, the GCLM does not indicate much texture change in the area, which is expected as they are all park/woodland areas\nHigh contrast at point 2, as this is the cultural and touristic center, notably including the Eiffel tower, small parks, Haussmannian 19th century buildings and recently built elements. So it is not a surprise that this area has high contrast values.\nFinally, area 3 follows part of the Seine. As this is the main water body in the city, we would expect high values of similarity which is is the case as there are many light pixels grouped together in that area!\nPCA in GEE\nAlthough not as intuitive as the rasterPCA in RStoolbox, PCA analysis is possible in GEE. we find that the first 4 clusters account for more than 98% of the total variance of the studied area.\n\n\nValues of PCA clusters (in %)\n\n\nBelow we have an illustration of the four main groups visible. We see that a great deal of the variance is captured in the first frame. This is not a surprise as Paris is an Urban area and has quite strong similarities in terms of colours, and does not have a lot of variance with big contrasts between urban and green areas for example (parks are quite small compared to other cities, say London).\n\n\nBand Maths\nNDVI\nThe Normalised Vegetation Index is the usual indicator of vegetation in an area. Here it makes sense that the values are higher in the park areas, closer to the outskirts of the city, than in the center which has a very high population density.\n\n\nThe Normalised Vegetation Index\n\n\nNDMI\nThe Normalised Moisture Index allows to collect information on the amount of moisture in the soil. The bands are calculated as follows in GEE:\n\nvar NDMI = clip.select('SR_B5').subtract(clip.select('SR_B6'))\n  .divide(clip.select('SR_B5').add(clip.select('SR_B6')))\n\nThe values go from -1 to 1, with the brown areas having the highest positive values. Again, most of the values are around 0 as the city has high building density. Nonetheless, the parks have high moisture value, with a strong brown colour.\n\n\nThe Normalised Moisture Index\n\n\nGCI\nThe Green Chlorophyll Index is an index that we have not analysed before but mentioned before. We thought using it in this project would be interesting to see the results but also it’s implementation in GEE. It was initially used in for MODIS ( Gitelson, Kaufman, and Merzlyak (1996) ) but as bands have similar characteristics between platforms, it can also be used on L-8.\n\nvar GCI = clip.select('SR_B5').divide(clip.select('SR_B5').add(1))\n\nBelow we have the illustration of the GCI. The values range between -1 and 1, with bright red representing a value of 1. In the case of Paris, we see that the values are mainly pinkish, representative of an urban environment, which is to be expected in Paris.\n\n\nThe Green Chlorophyll Index"
  },
  {
    "objectID": "GEE_intro.html",
    "href": "GEE_intro.html",
    "title": "Introduction to Google Earth Engine",
    "section": "",
    "text": "Personal Reflection\nUsing GEE was eye-opening, seeing how efficient getting access to satellite imagery was compared to using SNAP and other sources such as Copernicus Open Access Hub (for S-2) and Earth Explorer (for L-8).\nThis initial project was a very good opportunity to start getting accustomed to using JS and putting into practice. Although, I did not use much of my own code for this week (majoritarily inspired from CASA0023 and web-sources), I was still able to understand local areas and tweak the code accordingly! I was also able to build on the band math, using indices such as NDMI as my understanding of Javascript and Bands has improved.\nI was able to also add mote interactivity in the presentation of my findings, notably when presenting my findings for PCA an illustrating this in an embedded Google Slides using HTML and ‘iframe’ directly."
  }
]